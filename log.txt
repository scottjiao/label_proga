nohup: ignoring input
{'dataset': 'ogbn-arxiv', 'model': 'gcn', 'learning_rate': 0.001, 'epochs': 1000, 'dropout': 0.5, 'weight_decay': 0, 'early_stopping': 10, 'max_degree': 3, 'few_label_seed': 1, 'few_label_number': 10, 'confidence_threshold': 0.75, 'feature_normalize': 'True', 'with_psuedo_loss': 'False', 'standard_split': 'True', 'hidden_list': '[256,256,256]', 'exp_id': 'arxiv_std_gcn_0', 'repeat_times': 10}
Namespace(confidence_threshold=0.75, dataset='ogbn-arxiv', dropout=0.5, early_stopping=10, epochs=1000, exp_id='arxiv_std_gcn_0', exp_times='0', feature_normalize='True', few_label_number=10, few_label_seed=0, hidden_list='[256,256,256]', learning_rate=0.001, max_degree=3, model='gcn', standard_split='True', weight_decay=0.0, with_psuedo_loss='False')
(169343, 40)
(169343, 169343)
(169343, 128)
adj: (169343, 169343)
features: (169343, 128)
y: (169343, 40) (169343, 40) (169343, 40)
mask: (169343,) (169343,) (169343,)
x : tensor([[-0.0151, -0.0137, -0.0189,  ...,  0.0451, -0.0450, -0.0365],
        [-0.0580, -0.0329, -0.1515,  ...,  0.0319, -0.1733, -0.1402],
        [-0.0221, -0.0064, -0.0505,  ...,  0.0302,  0.0323, -0.0385],
        ...,
        [-0.0747, -0.0124, -0.1362,  ...,  0.0384, -0.0547, -0.0492],
        [-0.0492,  0.0146, -0.0896,  ..., -0.0318, -0.0147, -0.1339],
        [-0.0113,  0.1018, -0.0611,  ...,  0.0458,  0.0294, -0.0345]],
       device='cuda:0')
sp: tensor(indices=tensor([[     0,      1,      0,  ...,  75409, 138515, 169342],
                       [     0,      0,      1,  ..., 169342, 169342, 169342]]),
       values=tensor([0.5000, 0.3536, 0.3536,  ..., 0.0259, 0.0808, 0.0588]),
       device='cuda:0', size=(169343, 169343), nnz=2484941,
       layout=torch.sparse_coo)
input dim: 128
output dim: 40
num_features_nonzero: 0
Training epoch=0 train loss=20046.03515625 train acc=0.01925424113869667
test acc: 0.006995453033596277
Training epoch=10 train loss=16163.9296875 train acc=0.03687005862593651
test acc: 0.035038989037275314
Training epoch=20 train loss=13441.9453125 train acc=0.06052275374531746
test acc: 0.061025042086839676
Training epoch=30 train loss=17250.01953125 train acc=0.06873687356710434
test acc: 0.0703660324215889
Training epoch=40 train loss=14011.5205078125 train acc=0.048229072242975235
test acc: 0.0571158193051815
Training epoch=50 train loss=13095.380859375 train acc=0.05802663043141365
test acc: 0.049276791512966156
Training epoch=60 train loss=12010.72265625 train acc=0.06276597082614899
test acc: 0.04283686727285385
Training epoch=70 train loss=11044.4873046875 train acc=0.05357319489121437
test acc: 0.04277513921260834
Training epoch=80 train loss=9974.595703125 train acc=0.047877196222543716
test acc: 0.04390675574541092
Training epoch=90 train loss=9450.4306640625 train acc=0.05812560021877289
test acc: 0.044338829815387726
Training epoch=100 train loss=9769.9541015625 train acc=0.041730355471372604
test acc: 0.04518239572644234
Training epoch=110 train loss=7963.9775390625 train acc=0.0643274188041687
test acc: 0.03647923097014427
Training epoch=120 train loss=7520.9658203125 train acc=0.048042137175798416
test acc: 0.03189103677868843
Training epoch=130 train loss=6125.62548828125 train acc=0.042027249932289124
test acc: 0.02409316413104534
Training epoch=140 train loss=5361.80517578125 train acc=0.05072519928216934
test acc: 0.0211098063737154
Training epoch=150 train loss=5177.71875 train acc=0.037617798894643784
test acc: 0.020924635231494904
Training epoch=160 train loss=5825.16162109375 train acc=0.03878339007496834
test acc: 0.02014279179275036
Training epoch=170 train loss=4089.084228515625 train acc=0.031295016407966614
test acc: 0.019196344539523125
Training epoch=180 train loss=4289.009765625 train acc=0.027204452082514763
test acc: 0.0187025498598814
Training epoch=190 train loss=2749.856689453125 train acc=0.03630925714969635
test acc: 0.0184968002140522
Training epoch=200 train loss=3083.5615234375 train acc=0.022575076669454575
test acc: 0.018435075879096985
Training epoch=210 train loss=2554.62890625 train acc=0.024268481880426407
test acc: 0.018393926322460175
Training epoch=220 train loss=1857.79296875 train acc=0.024147523567080498
test acc: 0.018393926322460175
Training epoch=230 train loss=1556.1375732421875 train acc=0.020958643406629562
test acc: 0.018352776765823364
Training epoch=240 train loss=2054.715087890625 train acc=0.020243894308805466
test acc: 0.01837335154414177
Training epoch=250 train loss=1698.01220703125 train acc=0.019914012402296066
test acc: 0.01837335154414177
Training epoch=260 train loss=1533.4918212890625 train acc=0.019815044477581978
test acc: 0.01837335154414177
Training epoch=270 train loss=1515.5185546875 train acc=0.01949615590274334
test acc: 0.018352776765823364
Training epoch=280 train loss=1302.9237060546875 train acc=0.018605470657348633
test acc: 0.018352776765823364
Training epoch=290 train loss=1598.838134765625 train acc=0.018429532647132874
test acc: 0.018352776765823364
Training epoch=300 train loss=1109.285888671875 train acc=0.017967693507671356
test acc: 0.018352776765823364
Training epoch=310 train loss=1154.7347412109375 train acc=0.018418535590171814
test acc: 0.018352776765823364
Training epoch=320 train loss=1276.6610107421875 train acc=0.017582830041646957
test acc: 0.018352776765823364
Training epoch=330 train loss=1667.7474365234375 train acc=0.017725778743624687
test acc: 0.018352776765823364
Training epoch=340 train loss=1022.2053833007812 train acc=0.01721995510160923
test acc: 0.018352776765823364
Training epoch=350 train loss=1043.9451904296875 train acc=0.01709899678826332
test acc: 0.018352776765823364
Training epoch=360 train loss=524.2611083984375 train acc=0.01723095029592514
test acc: 0.018352776765823364
Training epoch=370 train loss=1200.01318359375 train acc=0.01713198609650135
test acc: 0.018352776765823364
Training epoch=380 train loss=1028.7113037109375 train acc=0.016725128516554832
test acc: 0.018352776765823364
Training epoch=390 train loss=997.7794799804688 train acc=0.016604172065854073
test acc: 0.018352776765823364
Training epoch=400 train loss=1138.5433349609375 train acc=0.016527198255062103
test acc: 0.018352776765823364
Training epoch=410 train loss=439.981201171875 train acc=0.016307277604937553
test acc: 0.018352776765823364
Training epoch=420 train loss=384.5028381347656 train acc=0.016010379418730736
test acc: 0.018352776765823364
Training epoch=430 train loss=1098.0645751953125 train acc=0.016131337732076645
test acc: 0.018352776765823364
Training epoch=440 train loss=850.0972290039062 train acc=0.016087353229522705
test acc: 0.018352776765823364
Training epoch=450 train loss=582.59130859375 train acc=0.015911415219306946
test acc: 0.018352776765823364
Training epoch=460 train loss=413.7496032714844 train acc=0.015955399721860886
test acc: 0.018352776765823364
Training epoch=470 train loss=339.73150634765625 train acc=0.015757469460368156
test acc: 0.018352776765823364
Training epoch=480 train loss=554.0471801757812 train acc=0.015735475346446037
test acc: 0.018352776765823364
Training epoch=490 train loss=684.1243896484375 train acc=0.015812451019883156
test acc: 0.018352776765823364
Training epoch=500 train loss=369.25408935546875 train acc=0.015614519827067852
test acc: 0.018352776765823364
Training epoch=510 train loss=477.6162109375 train acc=0.015702487900853157
test acc: 0.018352776765823364
Training epoch=520 train loss=431.3470458984375 train acc=0.016109345480799675
test acc: 0.018352776765823364
Training epoch=530 train loss=211.6956024169922 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=540 train loss=666.2645874023438 train acc=0.015625515952706337
test acc: 0.018352776765823364
Training epoch=550 train loss=315.9358215332031 train acc=0.015504557639360428
test acc: 0.018352776765823364
Training epoch=560 train loss=264.5771789550781 train acc=0.015449577011168003
test acc: 0.018352776765823364
Training epoch=570 train loss=226.6393280029297 train acc=0.015350611880421638
test acc: 0.018352776765823364
Training epoch=580 train loss=154.70286560058594 train acc=0.015504558570683002
test acc: 0.018352776765823364
Training epoch=590 train loss=297.6166687011719 train acc=0.015251646749675274
test acc: 0.018352776765823364
Training epoch=600 train loss=149.0151824951172 train acc=0.015449577011168003
test acc: 0.018352776765823364
Training epoch=610 train loss=314.4405212402344 train acc=0.015361608006060123
test acc: 0.018352776765823364
Training epoch=620 train loss=153.7670135498047 train acc=0.015317622572183609
test acc: 0.018352776765823364
Training epoch=630 train loss=172.78549194335938 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=640 train loss=97.95993041992188 train acc=0.015163677744567394
test acc: 0.018352776765823364
Training epoch=650 train loss=107.60059356689453 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=660 train loss=122.03556060791016 train acc=0.015460572205483913
test acc: 0.018352776765823364
Training epoch=670 train loss=634.636962890625 train acc=0.01510869525372982
test acc: 0.018352776765823364
Training epoch=680 train loss=108.26631927490234 train acc=0.015196666121482849
test acc: 0.018352776765823364
Training epoch=690 train loss=104.51615905761719 train acc=0.015163675881922245
test acc: 0.018352776765823364
Training epoch=700 train loss=115.58907318115234 train acc=0.015163675881922245
test acc: 0.018352776765823364
Training epoch=710 train loss=369.38873291015625 train acc=0.015174674801528454
test acc: 0.018352776765823364
Training epoch=720 train loss=91.96066284179688 train acc=0.01505371555685997
test acc: 0.018352776765823364
Training epoch=730 train loss=95.36050415039062 train acc=0.015218658372759819
test acc: 0.018352776765823364
Training epoch=740 train loss=105.92737579345703 train acc=0.015317624434828758
test acc: 0.018352776765823364
Training epoch=750 train loss=59.12226867675781 train acc=0.015141686424612999
test acc: 0.018352776765823364
Training epoch=760 train loss=117.86026000976562 train acc=0.01515268161892891
test acc: 0.018352776765823364
Training epoch=770 train loss=291.3061218261719 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=780 train loss=159.56521606445312 train acc=0.01506471261382103
test acc: 0.018352776765823364
Training epoch=790 train loss=86.24385833740234 train acc=0.01514168456196785
test acc: 0.018352776765823364
Training epoch=800 train loss=416.1731262207031 train acc=0.015075708739459515
test acc: 0.018352776765823364
Training epoch=810 train loss=208.1509552001953 train acc=0.015130690298974514
test acc: 0.018352776765823364
Training epoch=820 train loss=66.58364868164062 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=830 train loss=186.26687622070312 train acc=0.015031723305583
test acc: 0.018352776765823364
Training epoch=840 train loss=257.361572265625 train acc=0.01506471261382103
test acc: 0.018352776765823364
Training epoch=850 train loss=66.5474853515625 train acc=0.015130688436329365
test acc: 0.018352776765823364
Training epoch=860 train loss=219.64268493652344 train acc=0.01507570967078209
test acc: 0.018352776765823364
Training epoch=870 train loss=81.72249603271484 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=880 train loss=115.5125732421875 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=890 train loss=968.2783203125 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=900 train loss=50.06705856323242 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=910 train loss=501.2398986816406 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=920 train loss=40.806785583496094 train acc=0.015042721293866634
test acc: 0.018352776765823364
Training epoch=930 train loss=38.38389587402344 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=940 train loss=51.19314193725586 train acc=0.014888773672282696
test acc: 0.018352776765823364
Training epoch=950 train loss=282.293212890625 train acc=0.01498774066567421
test acc: 0.018352776765823364
Training epoch=960 train loss=348.9414978027344 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=970 train loss=63.99274444580078 train acc=0.01493275910615921
test acc: 0.018352776765823364
Training epoch=980 train loss=50.42446517944336 train acc=0.014921761117875576
test acc: 0.018352776765823364
Training epoch=990 train loss=171.4427032470703 train acc=0.01494375430047512
test acc: 0.018352776765823364
Namespace(confidence_threshold=0.75, dataset='ogbn-arxiv', dropout=0.5, early_stopping=10, epochs=1000, exp_id='arxiv_std_gcn_0', exp_times='1', feature_normalize='True', few_label_number=10, few_label_seed=1, hidden_list='[256,256,256]', learning_rate=0.001, max_degree=3, model='gcn', standard_split='True', weight_decay=0.0, with_psuedo_loss='False')
(169343, 40)
(169343, 169343)
(169343, 128)
adj: (169343, 169343)
features: (169343, 128)
y: (169343, 40) (169343, 40) (169343, 40)
mask: (169343,) (169343,) (169343,)
x : tensor([[-0.0151, -0.0137, -0.0189,  ...,  0.0451, -0.0450, -0.0365],
        [-0.0580, -0.0329, -0.1515,  ...,  0.0319, -0.1733, -0.1402],
        [-0.0221, -0.0064, -0.0505,  ...,  0.0302,  0.0323, -0.0385],
        ...,
        [-0.0747, -0.0124, -0.1362,  ...,  0.0384, -0.0547, -0.0492],
        [-0.0492,  0.0146, -0.0896,  ..., -0.0318, -0.0147, -0.1339],
        [-0.0113,  0.1018, -0.0611,  ...,  0.0458,  0.0294, -0.0345]],
       device='cuda:0')
sp: tensor(indices=tensor([[     0,      1,      0,  ...,  75409, 138515, 169342],
                       [     0,      0,      1,  ..., 169342, 169342, 169342]]),
       values=tensor([0.5000, 0.3536, 0.3536,  ..., 0.0259, 0.0808, 0.0588]),
       device='cuda:0', size=(169343, 169343), nnz=2484941,
       layout=torch.sparse_coo)
input dim: 128
output dim: 40
num_features_nonzero: 0
Training epoch=0 train loss=20046.03515625 train acc=0.01925424113869667
test acc: 0.006995453033596277
Training epoch=10 train loss=16163.9296875 train acc=0.03687005862593651
test acc: 0.035038989037275314
Training epoch=20 train loss=13441.9453125 train acc=0.06052275374531746
test acc: 0.061025042086839676
Training epoch=30 train loss=17250.01953125 train acc=0.06873687356710434
test acc: 0.0703660324215889
Training epoch=40 train loss=14011.5205078125 train acc=0.048229072242975235
test acc: 0.0571158193051815
Training epoch=50 train loss=13095.380859375 train acc=0.05802663043141365
test acc: 0.049276791512966156
Training epoch=60 train loss=12010.72265625 train acc=0.06276597082614899
test acc: 0.04283686727285385
Training epoch=70 train loss=11044.4873046875 train acc=0.05357319489121437
test acc: 0.04277513921260834
Training epoch=80 train loss=9974.595703125 train acc=0.047877196222543716
test acc: 0.04390675574541092
Training epoch=90 train loss=9450.4306640625 train acc=0.05812560021877289
test acc: 0.044338829815387726
Training epoch=100 train loss=9769.9541015625 train acc=0.041730355471372604
test acc: 0.04518239572644234
Training epoch=110 train loss=7963.9775390625 train acc=0.0643274188041687
test acc: 0.03647923097014427
Training epoch=120 train loss=7520.9658203125 train acc=0.048042137175798416
test acc: 0.03189103677868843
Training epoch=130 train loss=6125.62548828125 train acc=0.042027249932289124
test acc: 0.02409316413104534
Training epoch=140 train loss=5361.80517578125 train acc=0.05072519928216934
test acc: 0.0211098063737154
Training epoch=150 train loss=5177.71875 train acc=0.037617798894643784
test acc: 0.020924635231494904
Training epoch=160 train loss=5825.16162109375 train acc=0.03878339007496834
test acc: 0.02014279179275036
Training epoch=170 train loss=4089.084228515625 train acc=0.031295016407966614
test acc: 0.019196344539523125
Training epoch=180 train loss=4289.009765625 train acc=0.027204452082514763
test acc: 0.0187025498598814
Training epoch=190 train loss=2749.856689453125 train acc=0.03630925714969635
test acc: 0.0184968002140522
Training epoch=200 train loss=3083.5615234375 train acc=0.022575076669454575
test acc: 0.018435075879096985
Training epoch=210 train loss=2554.62890625 train acc=0.024268481880426407
test acc: 0.018393926322460175
Training epoch=220 train loss=1857.79296875 train acc=0.024147523567080498
test acc: 0.018393926322460175
Training epoch=230 train loss=1556.1375732421875 train acc=0.020958643406629562
test acc: 0.018352776765823364
Training epoch=240 train loss=2054.715087890625 train acc=0.020243894308805466
test acc: 0.01837335154414177
Training epoch=250 train loss=1698.01220703125 train acc=0.019914012402296066
test acc: 0.01837335154414177
Training epoch=260 train loss=1533.4918212890625 train acc=0.019815044477581978
test acc: 0.01837335154414177
Training epoch=270 train loss=1515.5185546875 train acc=0.01949615590274334
test acc: 0.018352776765823364
Training epoch=280 train loss=1302.9237060546875 train acc=0.018605470657348633
test acc: 0.018352776765823364
Training epoch=290 train loss=1598.838134765625 train acc=0.018429532647132874
test acc: 0.018352776765823364
Training epoch=300 train loss=1109.285888671875 train acc=0.017967693507671356
test acc: 0.018352776765823364
Training epoch=310 train loss=1154.7347412109375 train acc=0.018418535590171814
test acc: 0.018352776765823364
Training epoch=320 train loss=1276.6610107421875 train acc=0.017582830041646957
test acc: 0.018352776765823364
Training epoch=330 train loss=1667.7474365234375 train acc=0.017725778743624687
test acc: 0.018352776765823364
Training epoch=340 train loss=1022.2053833007812 train acc=0.01721995510160923
test acc: 0.018352776765823364
Training epoch=350 train loss=1043.9451904296875 train acc=0.01709899678826332
test acc: 0.018352776765823364
Training epoch=360 train loss=524.2611083984375 train acc=0.01723095029592514
test acc: 0.018352776765823364
Training epoch=370 train loss=1200.01318359375 train acc=0.01713198609650135
test acc: 0.018352776765823364
Training epoch=380 train loss=1028.7113037109375 train acc=0.016725128516554832
test acc: 0.018352776765823364
Training epoch=390 train loss=997.7794799804688 train acc=0.016604172065854073
test acc: 0.018352776765823364
Training epoch=400 train loss=1138.5433349609375 train acc=0.016527198255062103
test acc: 0.018352776765823364
Training epoch=410 train loss=439.981201171875 train acc=0.016307277604937553
test acc: 0.018352776765823364
Training epoch=420 train loss=384.5028381347656 train acc=0.016010379418730736
test acc: 0.018352776765823364
Training epoch=430 train loss=1098.0645751953125 train acc=0.016131337732076645
test acc: 0.018352776765823364
Training epoch=440 train loss=850.0972290039062 train acc=0.016087353229522705
test acc: 0.018352776765823364
Training epoch=450 train loss=582.59130859375 train acc=0.015911415219306946
test acc: 0.018352776765823364
Training epoch=460 train loss=413.7496032714844 train acc=0.015955399721860886
test acc: 0.018352776765823364
Training epoch=470 train loss=339.73150634765625 train acc=0.015757469460368156
test acc: 0.018352776765823364
Training epoch=480 train loss=554.0471801757812 train acc=0.015735475346446037
test acc: 0.018352776765823364
Training epoch=490 train loss=684.1243896484375 train acc=0.015812451019883156
test acc: 0.018352776765823364
Training epoch=500 train loss=369.25408935546875 train acc=0.015614519827067852
test acc: 0.018352776765823364
Training epoch=510 train loss=477.6162109375 train acc=0.015702487900853157
test acc: 0.018352776765823364
Training epoch=520 train loss=431.3470458984375 train acc=0.016109345480799675
test acc: 0.018352776765823364
Training epoch=530 train loss=211.6956024169922 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=540 train loss=666.2645874023438 train acc=0.015625515952706337
test acc: 0.018352776765823364
Training epoch=550 train loss=315.9358215332031 train acc=0.015504557639360428
test acc: 0.018352776765823364
Training epoch=560 train loss=264.5771789550781 train acc=0.015449577011168003
test acc: 0.018352776765823364
Training epoch=570 train loss=226.6393280029297 train acc=0.015350611880421638
test acc: 0.018352776765823364
Training epoch=580 train loss=154.70286560058594 train acc=0.015504558570683002
test acc: 0.018352776765823364
Training epoch=590 train loss=297.6166687011719 train acc=0.015251646749675274
test acc: 0.018352776765823364
Training epoch=600 train loss=149.0151824951172 train acc=0.015449577011168003
test acc: 0.018352776765823364
Training epoch=610 train loss=314.4405212402344 train acc=0.015361608006060123
test acc: 0.018352776765823364
Training epoch=620 train loss=153.7670135498047 train acc=0.015317622572183609
test acc: 0.018352776765823364
Training epoch=630 train loss=172.78549194335938 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=640 train loss=97.95993041992188 train acc=0.015163677744567394
test acc: 0.018352776765823364
Training epoch=650 train loss=107.60059356689453 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=660 train loss=122.03556060791016 train acc=0.015460572205483913
test acc: 0.018352776765823364
Training epoch=670 train loss=634.636962890625 train acc=0.01510869525372982
test acc: 0.018352776765823364
Training epoch=680 train loss=108.26631927490234 train acc=0.015196666121482849
test acc: 0.018352776765823364
Training epoch=690 train loss=104.51615905761719 train acc=0.015163675881922245
test acc: 0.018352776765823364
Training epoch=700 train loss=115.58907318115234 train acc=0.015163675881922245
test acc: 0.018352776765823364
Training epoch=710 train loss=369.38873291015625 train acc=0.015174674801528454
test acc: 0.018352776765823364
Training epoch=720 train loss=91.96066284179688 train acc=0.01505371555685997
test acc: 0.018352776765823364
Training epoch=730 train loss=95.36050415039062 train acc=0.015218658372759819
test acc: 0.018352776765823364
Training epoch=740 train loss=105.92737579345703 train acc=0.015317624434828758
test acc: 0.018352776765823364
Training epoch=750 train loss=59.12226867675781 train acc=0.015141686424612999
test acc: 0.018352776765823364
Training epoch=760 train loss=117.86026000976562 train acc=0.01515268161892891
test acc: 0.018352776765823364
Training epoch=770 train loss=291.3061218261719 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=780 train loss=159.56521606445312 train acc=0.01506471261382103
test acc: 0.018352776765823364
Training epoch=790 train loss=86.24385833740234 train acc=0.01514168456196785
test acc: 0.018352776765823364
Training epoch=800 train loss=416.1731262207031 train acc=0.015075708739459515
test acc: 0.018352776765823364
Training epoch=810 train loss=208.1509552001953 train acc=0.015130690298974514
test acc: 0.018352776765823364
Training epoch=820 train loss=66.58364868164062 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=830 train loss=186.26687622070312 train acc=0.015031723305583
test acc: 0.018352776765823364
Training epoch=840 train loss=257.361572265625 train acc=0.01506471261382103
test acc: 0.018352776765823364
Training epoch=850 train loss=66.5474853515625 train acc=0.015130688436329365
test acc: 0.018352776765823364
Training epoch=860 train loss=219.64268493652344 train acc=0.01507570967078209
test acc: 0.018352776765823364
Training epoch=870 train loss=81.72249603271484 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=880 train loss=115.5125732421875 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=890 train loss=968.2783203125 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=900 train loss=50.06705856323242 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=910 train loss=501.2398986816406 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=920 train loss=40.806785583496094 train acc=0.015042721293866634
test acc: 0.018352776765823364
Training epoch=930 train loss=38.38389587402344 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=940 train loss=51.19314193725586 train acc=0.014888773672282696
test acc: 0.018352776765823364
Training epoch=950 train loss=282.293212890625 train acc=0.01498774066567421
test acc: 0.018352776765823364
Training epoch=960 train loss=348.9414978027344 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=970 train loss=63.99274444580078 train acc=0.01493275910615921
test acc: 0.018352776765823364
Training epoch=980 train loss=50.42446517944336 train acc=0.014921761117875576
test acc: 0.018352776765823364
Training epoch=990 train loss=171.4427032470703 train acc=0.01494375430047512
test acc: 0.018352776765823364
Namespace(confidence_threshold=0.75, dataset='ogbn-arxiv', dropout=0.5, early_stopping=10, epochs=1000, exp_id='arxiv_std_gcn_0', exp_times='2', feature_normalize='True', few_label_number=10, few_label_seed=2, hidden_list='[256,256,256]', learning_rate=0.001, max_degree=3, model='gcn', standard_split='True', weight_decay=0.0, with_psuedo_loss='False')
(169343, 40)
(169343, 169343)
(169343, 128)
adj: (169343, 169343)
features: (169343, 128)
y: (169343, 40) (169343, 40) (169343, 40)
mask: (169343,) (169343,) (169343,)
x : tensor([[-0.0151, -0.0137, -0.0189,  ...,  0.0451, -0.0450, -0.0365],
        [-0.0580, -0.0329, -0.1515,  ...,  0.0319, -0.1733, -0.1402],
        [-0.0221, -0.0064, -0.0505,  ...,  0.0302,  0.0323, -0.0385],
        ...,
        [-0.0747, -0.0124, -0.1362,  ...,  0.0384, -0.0547, -0.0492],
        [-0.0492,  0.0146, -0.0896,  ..., -0.0318, -0.0147, -0.1339],
        [-0.0113,  0.1018, -0.0611,  ...,  0.0458,  0.0294, -0.0345]],
       device='cuda:0')
sp: tensor(indices=tensor([[     0,      1,      0,  ...,  75409, 138515, 169342],
                       [     0,      0,      1,  ..., 169342, 169342, 169342]]),
       values=tensor([0.5000, 0.3536, 0.3536,  ..., 0.0259, 0.0808, 0.0588]),
       device='cuda:0', size=(169343, 169343), nnz=2484941,
       layout=torch.sparse_coo)
input dim: 128
output dim: 40
num_features_nonzero: 0
Training epoch=0 train loss=20046.03515625 train acc=0.01925424113869667
test acc: 0.006995453033596277
Training epoch=10 train loss=16163.9296875 train acc=0.03687005862593651
test acc: 0.035038989037275314
Training epoch=20 train loss=13441.9453125 train acc=0.06052275374531746
test acc: 0.061025042086839676
Training epoch=30 train loss=17250.01953125 train acc=0.06873687356710434
test acc: 0.0703660324215889
Training epoch=40 train loss=14011.5205078125 train acc=0.048229072242975235
test acc: 0.0571158193051815
Training epoch=50 train loss=13095.380859375 train acc=0.05802663043141365
test acc: 0.049276791512966156
Training epoch=60 train loss=12010.72265625 train acc=0.06276597082614899
test acc: 0.04283686727285385
Training epoch=70 train loss=11044.4873046875 train acc=0.05357319489121437
test acc: 0.04277513921260834
Training epoch=80 train loss=9974.595703125 train acc=0.047877196222543716
test acc: 0.04390675574541092
Training epoch=90 train loss=9450.4306640625 train acc=0.05812560021877289
test acc: 0.044338829815387726
Training epoch=100 train loss=9769.9541015625 train acc=0.041730355471372604
test acc: 0.04518239572644234
Training epoch=110 train loss=7963.9775390625 train acc=0.0643274188041687
test acc: 0.03647923097014427
Training epoch=120 train loss=7520.9658203125 train acc=0.048042137175798416
test acc: 0.03189103677868843
Training epoch=130 train loss=6125.62548828125 train acc=0.042027249932289124
test acc: 0.02409316413104534
Training epoch=140 train loss=5361.80517578125 train acc=0.05072519928216934
test acc: 0.0211098063737154
Training epoch=150 train loss=5177.71875 train acc=0.037617798894643784
test acc: 0.020924635231494904
Training epoch=160 train loss=5825.16162109375 train acc=0.03878339007496834
test acc: 0.02014279179275036
Training epoch=170 train loss=4089.084228515625 train acc=0.031295016407966614
test acc: 0.019196344539523125
Training epoch=180 train loss=4289.009765625 train acc=0.027204452082514763
test acc: 0.0187025498598814
Training epoch=190 train loss=2749.856689453125 train acc=0.03630925714969635
test acc: 0.0184968002140522
Training epoch=200 train loss=3083.5615234375 train acc=0.022575076669454575
test acc: 0.018435075879096985
Training epoch=210 train loss=2554.62890625 train acc=0.024268481880426407
test acc: 0.018393926322460175
Training epoch=220 train loss=1857.79296875 train acc=0.024147523567080498
test acc: 0.018393926322460175
Training epoch=230 train loss=1556.1375732421875 train acc=0.020958643406629562
test acc: 0.018352776765823364
Training epoch=240 train loss=2054.715087890625 train acc=0.020243894308805466
test acc: 0.01837335154414177
Training epoch=250 train loss=1698.01220703125 train acc=0.019914012402296066
test acc: 0.01837335154414177
Training epoch=260 train loss=1533.4918212890625 train acc=0.019815044477581978
test acc: 0.01837335154414177
Training epoch=270 train loss=1515.5185546875 train acc=0.01949615590274334
test acc: 0.018352776765823364
Training epoch=280 train loss=1302.9237060546875 train acc=0.018605470657348633
test acc: 0.018352776765823364
Training epoch=290 train loss=1598.838134765625 train acc=0.018429532647132874
test acc: 0.018352776765823364
Training epoch=300 train loss=1109.285888671875 train acc=0.017967693507671356
test acc: 0.018352776765823364
Training epoch=310 train loss=1154.7347412109375 train acc=0.018418535590171814
test acc: 0.018352776765823364
Training epoch=320 train loss=1276.6610107421875 train acc=0.017582830041646957
test acc: 0.018352776765823364
Training epoch=330 train loss=1667.7474365234375 train acc=0.017725778743624687
test acc: 0.018352776765823364
Training epoch=340 train loss=1022.2053833007812 train acc=0.01721995510160923
test acc: 0.018352776765823364
Training epoch=350 train loss=1043.9451904296875 train acc=0.01709899678826332
test acc: 0.018352776765823364
Training epoch=360 train loss=524.2611083984375 train acc=0.01723095029592514
test acc: 0.018352776765823364
Training epoch=370 train loss=1200.01318359375 train acc=0.01713198609650135
test acc: 0.018352776765823364
Training epoch=380 train loss=1028.7113037109375 train acc=0.016725128516554832
test acc: 0.018352776765823364
Training epoch=390 train loss=997.7794799804688 train acc=0.016604172065854073
test acc: 0.018352776765823364
Training epoch=400 train loss=1138.5433349609375 train acc=0.016527198255062103
test acc: 0.018352776765823364
Training epoch=410 train loss=439.981201171875 train acc=0.016307277604937553
test acc: 0.018352776765823364
Training epoch=420 train loss=384.5028381347656 train acc=0.016010379418730736
test acc: 0.018352776765823364
Training epoch=430 train loss=1098.0645751953125 train acc=0.016131337732076645
test acc: 0.018352776765823364
Training epoch=440 train loss=850.0972290039062 train acc=0.016087353229522705
test acc: 0.018352776765823364
Training epoch=450 train loss=582.59130859375 train acc=0.015911415219306946
test acc: 0.018352776765823364
Training epoch=460 train loss=413.7496032714844 train acc=0.015955399721860886
test acc: 0.018352776765823364
Training epoch=470 train loss=339.73150634765625 train acc=0.015757469460368156
test acc: 0.018352776765823364
Training epoch=480 train loss=554.0471801757812 train acc=0.015735475346446037
test acc: 0.018352776765823364
Training epoch=490 train loss=684.1243896484375 train acc=0.015812451019883156
test acc: 0.018352776765823364
Training epoch=500 train loss=369.25408935546875 train acc=0.015614519827067852
test acc: 0.018352776765823364
Training epoch=510 train loss=477.6162109375 train acc=0.015702487900853157
test acc: 0.018352776765823364
Training epoch=520 train loss=431.3470458984375 train acc=0.016109345480799675
test acc: 0.018352776765823364
Training epoch=530 train loss=211.6956024169922 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=540 train loss=666.2645874023438 train acc=0.015625515952706337
test acc: 0.018352776765823364
Training epoch=550 train loss=315.9358215332031 train acc=0.015504557639360428
test acc: 0.018352776765823364
Training epoch=560 train loss=264.5771789550781 train acc=0.015449577011168003
test acc: 0.018352776765823364
Training epoch=570 train loss=226.6393280029297 train acc=0.015350611880421638
test acc: 0.018352776765823364
Training epoch=580 train loss=154.70286560058594 train acc=0.015504558570683002
test acc: 0.018352776765823364
Training epoch=590 train loss=297.6166687011719 train acc=0.015251646749675274
test acc: 0.018352776765823364
Training epoch=600 train loss=149.0151824951172 train acc=0.015449577011168003
test acc: 0.018352776765823364
Training epoch=610 train loss=314.4405212402344 train acc=0.015361608006060123
test acc: 0.018352776765823364
Training epoch=620 train loss=153.7670135498047 train acc=0.015317622572183609
test acc: 0.018352776765823364
Training epoch=630 train loss=172.78549194335938 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=640 train loss=97.95993041992188 train acc=0.015163677744567394
test acc: 0.018352776765823364
Training epoch=650 train loss=107.60059356689453 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=660 train loss=122.03556060791016 train acc=0.015460572205483913
test acc: 0.018352776765823364
Training epoch=670 train loss=634.636962890625 train acc=0.01510869525372982
test acc: 0.018352776765823364
Training epoch=680 train loss=108.26631927490234 train acc=0.015196666121482849
test acc: 0.018352776765823364
Training epoch=690 train loss=104.51615905761719 train acc=0.015163675881922245
test acc: 0.018352776765823364
Training epoch=700 train loss=115.58907318115234 train acc=0.015163675881922245
test acc: 0.018352776765823364
Training epoch=710 train loss=369.38873291015625 train acc=0.015174674801528454
test acc: 0.018352776765823364
Training epoch=720 train loss=91.96066284179688 train acc=0.01505371555685997
test acc: 0.018352776765823364
Training epoch=730 train loss=95.36050415039062 train acc=0.015218658372759819
test acc: 0.018352776765823364
Training epoch=740 train loss=105.92737579345703 train acc=0.015317624434828758
test acc: 0.018352776765823364
Training epoch=750 train loss=59.12226867675781 train acc=0.015141686424612999
test acc: 0.018352776765823364
Training epoch=760 train loss=117.86026000976562 train acc=0.01515268161892891
test acc: 0.018352776765823364
Training epoch=770 train loss=291.3061218261719 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=780 train loss=159.56521606445312 train acc=0.01506471261382103
test acc: 0.018352776765823364
Training epoch=790 train loss=86.24385833740234 train acc=0.01514168456196785
test acc: 0.018352776765823364
Training epoch=800 train loss=416.1731262207031 train acc=0.015075708739459515
test acc: 0.018352776765823364
Training epoch=810 train loss=208.1509552001953 train acc=0.015130690298974514
test acc: 0.018352776765823364
Training epoch=820 train loss=66.58364868164062 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=830 train loss=186.26687622070312 train acc=0.015031723305583
test acc: 0.018352776765823364
Training epoch=840 train loss=257.361572265625 train acc=0.01506471261382103
test acc: 0.018352776765823364
Training epoch=850 train loss=66.5474853515625 train acc=0.015130688436329365
test acc: 0.018352776765823364
Training epoch=860 train loss=219.64268493652344 train acc=0.01507570967078209
test acc: 0.018352776765823364
Training epoch=870 train loss=81.72249603271484 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=880 train loss=115.5125732421875 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=890 train loss=968.2783203125 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=900 train loss=50.06705856323242 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=910 train loss=501.2398986816406 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=920 train loss=40.806785583496094 train acc=0.015042721293866634
test acc: 0.018352776765823364
Training epoch=930 train loss=38.38389587402344 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=940 train loss=51.19314193725586 train acc=0.014888773672282696
test acc: 0.018352776765823364
Training epoch=950 train loss=282.293212890625 train acc=0.01498774066567421
test acc: 0.018352776765823364
Training epoch=960 train loss=348.9414978027344 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=970 train loss=63.99274444580078 train acc=0.01493275910615921
test acc: 0.018352776765823364
Training epoch=980 train loss=50.42446517944336 train acc=0.014921761117875576
test acc: 0.018352776765823364
Training epoch=990 train loss=171.4427032470703 train acc=0.01494375430047512
test acc: 0.018352776765823364
Namespace(confidence_threshold=0.75, dataset='ogbn-arxiv', dropout=0.5, early_stopping=10, epochs=1000, exp_id='arxiv_std_gcn_0', exp_times='3', feature_normalize='True', few_label_number=10, few_label_seed=3, hidden_list='[256,256,256]', learning_rate=0.001, max_degree=3, model='gcn', standard_split='True', weight_decay=0.0, with_psuedo_loss='False')
(169343, 40)
(169343, 169343)
(169343, 128)
adj: (169343, 169343)
features: (169343, 128)
y: (169343, 40) (169343, 40) (169343, 40)
mask: (169343,) (169343,) (169343,)
x : tensor([[-0.0151, -0.0137, -0.0189,  ...,  0.0451, -0.0450, -0.0365],
        [-0.0580, -0.0329, -0.1515,  ...,  0.0319, -0.1733, -0.1402],
        [-0.0221, -0.0064, -0.0505,  ...,  0.0302,  0.0323, -0.0385],
        ...,
        [-0.0747, -0.0124, -0.1362,  ...,  0.0384, -0.0547, -0.0492],
        [-0.0492,  0.0146, -0.0896,  ..., -0.0318, -0.0147, -0.1339],
        [-0.0113,  0.1018, -0.0611,  ...,  0.0458,  0.0294, -0.0345]],
       device='cuda:0')
sp: tensor(indices=tensor([[     0,      1,      0,  ...,  75409, 138515, 169342],
                       [     0,      0,      1,  ..., 169342, 169342, 169342]]),
       values=tensor([0.5000, 0.3536, 0.3536,  ..., 0.0259, 0.0808, 0.0588]),
       device='cuda:0', size=(169343, 169343), nnz=2484941,
       layout=torch.sparse_coo)
input dim: 128
output dim: 40
num_features_nonzero: 0
Training epoch=0 train loss=20046.03515625 train acc=0.01925424113869667
test acc: 0.006995453033596277
Training epoch=10 train loss=16163.9296875 train acc=0.03687005862593651
test acc: 0.035038989037275314
Training epoch=20 train loss=13441.9453125 train acc=0.06052275374531746
test acc: 0.061025042086839676
Training epoch=30 train loss=17250.01953125 train acc=0.06873687356710434
test acc: 0.0703660324215889
Training epoch=40 train loss=14011.5205078125 train acc=0.048229072242975235
test acc: 0.0571158193051815
Training epoch=50 train loss=13095.380859375 train acc=0.05802663043141365
test acc: 0.049276791512966156
Training epoch=60 train loss=12010.72265625 train acc=0.06276597082614899
test acc: 0.04283686727285385
Training epoch=70 train loss=11044.4873046875 train acc=0.05357319489121437
test acc: 0.04277513921260834
Training epoch=80 train loss=9974.595703125 train acc=0.047877196222543716
test acc: 0.04390675574541092
Training epoch=90 train loss=9450.4306640625 train acc=0.05812560021877289
test acc: 0.044338829815387726
Training epoch=100 train loss=9769.9541015625 train acc=0.041730355471372604
test acc: 0.04518239572644234
Training epoch=110 train loss=7963.9775390625 train acc=0.0643274188041687
test acc: 0.03647923097014427
Training epoch=120 train loss=7520.9658203125 train acc=0.048042137175798416
test acc: 0.03189103677868843
Training epoch=130 train loss=6125.62548828125 train acc=0.042027249932289124
test acc: 0.02409316413104534
Training epoch=140 train loss=5361.80517578125 train acc=0.05072519928216934
test acc: 0.0211098063737154
Training epoch=150 train loss=5177.71875 train acc=0.037617798894643784
test acc: 0.020924635231494904
Training epoch=160 train loss=5825.16162109375 train acc=0.03878339007496834
test acc: 0.02014279179275036
Training epoch=170 train loss=4089.084228515625 train acc=0.031295016407966614
test acc: 0.019196344539523125
Training epoch=180 train loss=4289.009765625 train acc=0.027204452082514763
test acc: 0.0187025498598814
Training epoch=190 train loss=2749.856689453125 train acc=0.03630925714969635
test acc: 0.0184968002140522
Training epoch=200 train loss=3083.5615234375 train acc=0.022575076669454575
test acc: 0.018435075879096985
Training epoch=210 train loss=2554.62890625 train acc=0.024268481880426407
test acc: 0.018393926322460175
Training epoch=220 train loss=1857.79296875 train acc=0.024147523567080498
test acc: 0.018393926322460175
Training epoch=230 train loss=1556.1375732421875 train acc=0.020958643406629562
test acc: 0.018352776765823364
Training epoch=240 train loss=2054.715087890625 train acc=0.020243894308805466
test acc: 0.01837335154414177
Training epoch=250 train loss=1698.01220703125 train acc=0.019914012402296066
test acc: 0.01837335154414177
Training epoch=260 train loss=1533.4918212890625 train acc=0.019815044477581978
test acc: 0.01837335154414177
Training epoch=270 train loss=1515.5185546875 train acc=0.01949615590274334
test acc: 0.018352776765823364
Training epoch=280 train loss=1302.9237060546875 train acc=0.018605470657348633
test acc: 0.018352776765823364
Training epoch=290 train loss=1598.838134765625 train acc=0.018429532647132874
test acc: 0.018352776765823364
Training epoch=300 train loss=1109.285888671875 train acc=0.017967693507671356
test acc: 0.018352776765823364
Training epoch=310 train loss=1154.7347412109375 train acc=0.018418535590171814
test acc: 0.018352776765823364
Training epoch=320 train loss=1276.6610107421875 train acc=0.017582830041646957
test acc: 0.018352776765823364
Training epoch=330 train loss=1667.7474365234375 train acc=0.017725778743624687
test acc: 0.018352776765823364
Training epoch=340 train loss=1022.2053833007812 train acc=0.01721995510160923
test acc: 0.018352776765823364
Training epoch=350 train loss=1043.9451904296875 train acc=0.01709899678826332
test acc: 0.018352776765823364
Training epoch=360 train loss=524.2611083984375 train acc=0.01723095029592514
test acc: 0.018352776765823364
Training epoch=370 train loss=1200.01318359375 train acc=0.01713198609650135
test acc: 0.018352776765823364
Training epoch=380 train loss=1028.7113037109375 train acc=0.016725128516554832
test acc: 0.018352776765823364
Training epoch=390 train loss=997.7794799804688 train acc=0.016604172065854073
test acc: 0.018352776765823364
Training epoch=400 train loss=1138.5433349609375 train acc=0.016527198255062103
test acc: 0.018352776765823364
Training epoch=410 train loss=439.981201171875 train acc=0.016307277604937553
test acc: 0.018352776765823364
Training epoch=420 train loss=384.5028381347656 train acc=0.016010379418730736
test acc: 0.018352776765823364
Training epoch=430 train loss=1098.0645751953125 train acc=0.016131337732076645
test acc: 0.018352776765823364
Training epoch=440 train loss=850.0972290039062 train acc=0.016087353229522705
test acc: 0.018352776765823364
Training epoch=450 train loss=582.59130859375 train acc=0.015911415219306946
test acc: 0.018352776765823364
Training epoch=460 train loss=413.7496032714844 train acc=0.015955399721860886
test acc: 0.018352776765823364
Training epoch=470 train loss=339.73150634765625 train acc=0.015757469460368156
test acc: 0.018352776765823364
Training epoch=480 train loss=554.0471801757812 train acc=0.015735475346446037
test acc: 0.018352776765823364
Training epoch=490 train loss=684.1243896484375 train acc=0.015812451019883156
test acc: 0.018352776765823364
Training epoch=500 train loss=369.25408935546875 train acc=0.015614519827067852
test acc: 0.018352776765823364
Training epoch=510 train loss=477.6162109375 train acc=0.015702487900853157
test acc: 0.018352776765823364
Training epoch=520 train loss=431.3470458984375 train acc=0.016109345480799675
test acc: 0.018352776765823364
Training epoch=530 train loss=211.6956024169922 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=540 train loss=666.2645874023438 train acc=0.015625515952706337
test acc: 0.018352776765823364
Training epoch=550 train loss=315.9358215332031 train acc=0.015504557639360428
test acc: 0.018352776765823364
Training epoch=560 train loss=264.5771789550781 train acc=0.015449577011168003
test acc: 0.018352776765823364
Training epoch=570 train loss=226.6393280029297 train acc=0.015350611880421638
test acc: 0.018352776765823364
Training epoch=580 train loss=154.70286560058594 train acc=0.015504558570683002
test acc: 0.018352776765823364
Training epoch=590 train loss=297.6166687011719 train acc=0.015251646749675274
test acc: 0.018352776765823364
Training epoch=600 train loss=149.0151824951172 train acc=0.015449577011168003
test acc: 0.018352776765823364
Training epoch=610 train loss=314.4405212402344 train acc=0.015361608006060123
test acc: 0.018352776765823364
Training epoch=620 train loss=153.7670135498047 train acc=0.015317622572183609
test acc: 0.018352776765823364
Training epoch=630 train loss=172.78549194335938 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=640 train loss=97.95993041992188 train acc=0.015163677744567394
test acc: 0.018352776765823364
Training epoch=650 train loss=107.60059356689453 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=660 train loss=122.03556060791016 train acc=0.015460572205483913
test acc: 0.018352776765823364
Training epoch=670 train loss=634.636962890625 train acc=0.01510869525372982
test acc: 0.018352776765823364
Training epoch=680 train loss=108.26631927490234 train acc=0.015196666121482849
test acc: 0.018352776765823364
Training epoch=690 train loss=104.51615905761719 train acc=0.015163675881922245
test acc: 0.018352776765823364
Training epoch=700 train loss=115.58907318115234 train acc=0.015163675881922245
test acc: 0.018352776765823364
Training epoch=710 train loss=369.38873291015625 train acc=0.015174674801528454
test acc: 0.018352776765823364
Training epoch=720 train loss=91.96066284179688 train acc=0.01505371555685997
test acc: 0.018352776765823364
Training epoch=730 train loss=95.36050415039062 train acc=0.015218658372759819
test acc: 0.018352776765823364
Training epoch=740 train loss=105.92737579345703 train acc=0.015317624434828758
test acc: 0.018352776765823364
Training epoch=750 train loss=59.12226867675781 train acc=0.015141686424612999
test acc: 0.018352776765823364
Training epoch=760 train loss=117.86026000976562 train acc=0.01515268161892891
test acc: 0.018352776765823364
Training epoch=770 train loss=291.3061218261719 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=780 train loss=159.56521606445312 train acc=0.01506471261382103
test acc: 0.018352776765823364
Training epoch=790 train loss=86.24385833740234 train acc=0.01514168456196785
test acc: 0.018352776765823364
Training epoch=800 train loss=416.1731262207031 train acc=0.015075708739459515
test acc: 0.018352776765823364
Training epoch=810 train loss=208.1509552001953 train acc=0.015130690298974514
test acc: 0.018352776765823364
Training epoch=820 train loss=66.58364868164062 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=830 train loss=186.26687622070312 train acc=0.015031723305583
test acc: 0.018352776765823364
Training epoch=840 train loss=257.361572265625 train acc=0.01506471261382103
test acc: 0.018352776765823364
Training epoch=850 train loss=66.5474853515625 train acc=0.015130688436329365
test acc: 0.018352776765823364
Training epoch=860 train loss=219.64268493652344 train acc=0.01507570967078209
test acc: 0.018352776765823364
Training epoch=870 train loss=81.72249603271484 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=880 train loss=115.5125732421875 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=890 train loss=968.2783203125 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=900 train loss=50.06705856323242 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=910 train loss=501.2398986816406 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=920 train loss=40.806785583496094 train acc=0.015042721293866634
test acc: 0.018352776765823364
Training epoch=930 train loss=38.38389587402344 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=940 train loss=51.19314193725586 train acc=0.014888773672282696
test acc: 0.018352776765823364
Training epoch=950 train loss=282.293212890625 train acc=0.01498774066567421
test acc: 0.018352776765823364
Training epoch=960 train loss=348.9414978027344 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=970 train loss=63.99274444580078 train acc=0.01493275910615921
test acc: 0.018352776765823364
Training epoch=980 train loss=50.42446517944336 train acc=0.014921761117875576
test acc: 0.018352776765823364
Training epoch=990 train loss=171.4427032470703 train acc=0.01494375430047512
test acc: 0.018352776765823364
Namespace(confidence_threshold=0.75, dataset='ogbn-arxiv', dropout=0.5, early_stopping=10, epochs=1000, exp_id='arxiv_std_gcn_0', exp_times='4', feature_normalize='True', few_label_number=10, few_label_seed=4, hidden_list='[256,256,256]', learning_rate=0.001, max_degree=3, model='gcn', standard_split='True', weight_decay=0.0, with_psuedo_loss='False')
(169343, 40)
(169343, 169343)
(169343, 128)
adj: (169343, 169343)
features: (169343, 128)
y: (169343, 40) (169343, 40) (169343, 40)
mask: (169343,) (169343,) (169343,)
x : tensor([[-0.0151, -0.0137, -0.0189,  ...,  0.0451, -0.0450, -0.0365],
        [-0.0580, -0.0329, -0.1515,  ...,  0.0319, -0.1733, -0.1402],
        [-0.0221, -0.0064, -0.0505,  ...,  0.0302,  0.0323, -0.0385],
        ...,
        [-0.0747, -0.0124, -0.1362,  ...,  0.0384, -0.0547, -0.0492],
        [-0.0492,  0.0146, -0.0896,  ..., -0.0318, -0.0147, -0.1339],
        [-0.0113,  0.1018, -0.0611,  ...,  0.0458,  0.0294, -0.0345]],
       device='cuda:0')
sp: tensor(indices=tensor([[     0,      1,      0,  ...,  75409, 138515, 169342],
                       [     0,      0,      1,  ..., 169342, 169342, 169342]]),
       values=tensor([0.5000, 0.3536, 0.3536,  ..., 0.0259, 0.0808, 0.0588]),
       device='cuda:0', size=(169343, 169343), nnz=2484941,
       layout=torch.sparse_coo)
input dim: 128
output dim: 40
num_features_nonzero: 0
Training epoch=0 train loss=20046.03515625 train acc=0.01925424113869667
test acc: 0.006995453033596277
Training epoch=10 train loss=16163.9296875 train acc=0.03687005862593651
test acc: 0.035038989037275314
Training epoch=20 train loss=13441.9453125 train acc=0.06052275374531746
test acc: 0.061025042086839676
Training epoch=30 train loss=17250.01953125 train acc=0.06873687356710434
test acc: 0.0703660324215889
Training epoch=40 train loss=14011.5205078125 train acc=0.048229072242975235
test acc: 0.0571158193051815
Training epoch=50 train loss=13095.380859375 train acc=0.05802663043141365
test acc: 0.049276791512966156
Training epoch=60 train loss=12010.72265625 train acc=0.06276597082614899
test acc: 0.04283686727285385
Training epoch=70 train loss=11044.4873046875 train acc=0.05357319489121437
test acc: 0.04277513921260834
Training epoch=80 train loss=9974.595703125 train acc=0.047877196222543716
test acc: 0.04390675574541092
Training epoch=90 train loss=9450.4306640625 train acc=0.05812560021877289
test acc: 0.044338829815387726
Training epoch=100 train loss=9769.9541015625 train acc=0.041730355471372604
test acc: 0.04518239572644234
Training epoch=110 train loss=7963.9775390625 train acc=0.0643274188041687
test acc: 0.03647923097014427
Training epoch=120 train loss=7520.9658203125 train acc=0.048042137175798416
test acc: 0.03189103677868843
Training epoch=130 train loss=6125.62548828125 train acc=0.042027249932289124
test acc: 0.02409316413104534
Training epoch=140 train loss=5361.80517578125 train acc=0.05072519928216934
test acc: 0.0211098063737154
Training epoch=150 train loss=5177.71875 train acc=0.037617798894643784
test acc: 0.020924635231494904
Training epoch=160 train loss=5825.16162109375 train acc=0.03878339007496834
test acc: 0.02014279179275036
Training epoch=170 train loss=4089.084228515625 train acc=0.031295016407966614
test acc: 0.019196344539523125
Training epoch=180 train loss=4289.009765625 train acc=0.027204452082514763
test acc: 0.0187025498598814
Training epoch=190 train loss=2749.856689453125 train acc=0.03630925714969635
test acc: 0.0184968002140522
Training epoch=200 train loss=3083.5615234375 train acc=0.022575076669454575
test acc: 0.018435075879096985
Training epoch=210 train loss=2554.62890625 train acc=0.024268481880426407
test acc: 0.018393926322460175
Training epoch=220 train loss=1857.79296875 train acc=0.024147523567080498
test acc: 0.018393926322460175
Training epoch=230 train loss=1556.1375732421875 train acc=0.020958643406629562
test acc: 0.018352776765823364
Training epoch=240 train loss=2054.715087890625 train acc=0.020243894308805466
test acc: 0.01837335154414177
Training epoch=250 train loss=1698.01220703125 train acc=0.019914012402296066
test acc: 0.01837335154414177
Training epoch=260 train loss=1533.4918212890625 train acc=0.019815044477581978
test acc: 0.01837335154414177
Training epoch=270 train loss=1515.5185546875 train acc=0.01949615590274334
test acc: 0.018352776765823364
Training epoch=280 train loss=1302.9237060546875 train acc=0.018605470657348633
test acc: 0.018352776765823364
Training epoch=290 train loss=1598.838134765625 train acc=0.018429532647132874
test acc: 0.018352776765823364
Training epoch=300 train loss=1109.285888671875 train acc=0.017967693507671356
test acc: 0.018352776765823364
Training epoch=310 train loss=1154.7347412109375 train acc=0.018418535590171814
test acc: 0.018352776765823364
Training epoch=320 train loss=1276.6610107421875 train acc=0.017582830041646957
test acc: 0.018352776765823364
Training epoch=330 train loss=1667.7474365234375 train acc=0.017725778743624687
test acc: 0.018352776765823364
Training epoch=340 train loss=1022.2053833007812 train acc=0.01721995510160923
test acc: 0.018352776765823364
Training epoch=350 train loss=1043.9451904296875 train acc=0.01709899678826332
test acc: 0.018352776765823364
Training epoch=360 train loss=524.2611083984375 train acc=0.01723095029592514
test acc: 0.018352776765823364
Training epoch=370 train loss=1200.01318359375 train acc=0.01713198609650135
test acc: 0.018352776765823364
Training epoch=380 train loss=1028.7113037109375 train acc=0.016725128516554832
test acc: 0.018352776765823364
Training epoch=390 train loss=997.7794799804688 train acc=0.016604172065854073
test acc: 0.018352776765823364
Training epoch=400 train loss=1138.5433349609375 train acc=0.016527198255062103
test acc: 0.018352776765823364
Training epoch=410 train loss=439.981201171875 train acc=0.016307277604937553
test acc: 0.018352776765823364
Training epoch=420 train loss=384.5028381347656 train acc=0.016010379418730736
test acc: 0.018352776765823364
Training epoch=430 train loss=1098.0645751953125 train acc=0.016131337732076645
test acc: 0.018352776765823364
Training epoch=440 train loss=850.0972290039062 train acc=0.016087353229522705
test acc: 0.018352776765823364
Training epoch=450 train loss=582.59130859375 train acc=0.015911415219306946
test acc: 0.018352776765823364
Training epoch=460 train loss=413.7496032714844 train acc=0.015955399721860886
test acc: 0.018352776765823364
Training epoch=470 train loss=339.73150634765625 train acc=0.015757469460368156
test acc: 0.018352776765823364
Training epoch=480 train loss=554.0471801757812 train acc=0.015735475346446037
test acc: 0.018352776765823364
Training epoch=490 train loss=684.1243896484375 train acc=0.015812451019883156
test acc: 0.018352776765823364
Training epoch=500 train loss=369.25408935546875 train acc=0.015614519827067852
test acc: 0.018352776765823364
Training epoch=510 train loss=477.6162109375 train acc=0.015702487900853157
test acc: 0.018352776765823364
Training epoch=520 train loss=431.3470458984375 train acc=0.016109345480799675
test acc: 0.018352776765823364
Training epoch=530 train loss=211.6956024169922 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=540 train loss=666.2645874023438 train acc=0.015625515952706337
test acc: 0.018352776765823364
Training epoch=550 train loss=315.9358215332031 train acc=0.015504557639360428
test acc: 0.018352776765823364
Training epoch=560 train loss=264.5771789550781 train acc=0.015449577011168003
test acc: 0.018352776765823364
Training epoch=570 train loss=226.6393280029297 train acc=0.015350611880421638
test acc: 0.018352776765823364
Training epoch=580 train loss=154.70286560058594 train acc=0.015504558570683002
test acc: 0.018352776765823364
Training epoch=590 train loss=297.6166687011719 train acc=0.015251646749675274
test acc: 0.018352776765823364
Training epoch=600 train loss=149.0151824951172 train acc=0.015449577011168003
test acc: 0.018352776765823364
Training epoch=610 train loss=314.4405212402344 train acc=0.015361608006060123
test acc: 0.018352776765823364
Training epoch=620 train loss=153.7670135498047 train acc=0.015317622572183609
test acc: 0.018352776765823364
Training epoch=630 train loss=172.78549194335938 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=640 train loss=97.95993041992188 train acc=0.015163677744567394
test acc: 0.018352776765823364
Training epoch=650 train loss=107.60059356689453 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=660 train loss=122.03556060791016 train acc=0.015460572205483913
test acc: 0.018352776765823364
Training epoch=670 train loss=634.636962890625 train acc=0.01510869525372982
test acc: 0.018352776765823364
Training epoch=680 train loss=108.26631927490234 train acc=0.015196666121482849
test acc: 0.018352776765823364
Training epoch=690 train loss=104.51615905761719 train acc=0.015163675881922245
test acc: 0.018352776765823364
Training epoch=700 train loss=115.58907318115234 train acc=0.015163675881922245
test acc: 0.018352776765823364
Training epoch=710 train loss=369.38873291015625 train acc=0.015174674801528454
test acc: 0.018352776765823364
Training epoch=720 train loss=91.96066284179688 train acc=0.01505371555685997
test acc: 0.018352776765823364
Training epoch=730 train loss=95.36050415039062 train acc=0.015218658372759819
test acc: 0.018352776765823364
Training epoch=740 train loss=105.92737579345703 train acc=0.015317624434828758
test acc: 0.018352776765823364
Training epoch=750 train loss=59.12226867675781 train acc=0.015141686424612999
test acc: 0.018352776765823364
Training epoch=760 train loss=117.86026000976562 train acc=0.01515268161892891
test acc: 0.018352776765823364
Training epoch=770 train loss=291.3061218261719 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=780 train loss=159.56521606445312 train acc=0.01506471261382103
test acc: 0.018352776765823364
Training epoch=790 train loss=86.24385833740234 train acc=0.01514168456196785
test acc: 0.018352776765823364
Training epoch=800 train loss=416.1731262207031 train acc=0.015075708739459515
test acc: 0.018352776765823364
Training epoch=810 train loss=208.1509552001953 train acc=0.015130690298974514
test acc: 0.018352776765823364
Training epoch=820 train loss=66.58364868164062 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=830 train loss=186.26687622070312 train acc=0.015031723305583
test acc: 0.018352776765823364
Training epoch=840 train loss=257.361572265625 train acc=0.01506471261382103
test acc: 0.018352776765823364
Training epoch=850 train loss=66.5474853515625 train acc=0.015130688436329365
test acc: 0.018352776765823364
Training epoch=860 train loss=219.64268493652344 train acc=0.01507570967078209
test acc: 0.018352776765823364
Training epoch=870 train loss=81.72249603271484 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=880 train loss=115.5125732421875 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=890 train loss=968.2783203125 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=900 train loss=50.06705856323242 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=910 train loss=501.2398986816406 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=920 train loss=40.806785583496094 train acc=0.015042721293866634
test acc: 0.018352776765823364
Training epoch=930 train loss=38.38389587402344 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=940 train loss=51.19314193725586 train acc=0.014888773672282696
test acc: 0.018352776765823364
Training epoch=950 train loss=282.293212890625 train acc=0.01498774066567421
test acc: 0.018352776765823364
Training epoch=960 train loss=348.9414978027344 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=970 train loss=63.99274444580078 train acc=0.01493275910615921
test acc: 0.018352776765823364
Training epoch=980 train loss=50.42446517944336 train acc=0.014921761117875576
test acc: 0.018352776765823364
Training epoch=990 train loss=171.4427032470703 train acc=0.01494375430047512
test acc: 0.018352776765823364
Namespace(confidence_threshold=0.75, dataset='ogbn-arxiv', dropout=0.5, early_stopping=10, epochs=1000, exp_id='arxiv_std_gcn_0', exp_times='5', feature_normalize='True', few_label_number=10, few_label_seed=5, hidden_list='[256,256,256]', learning_rate=0.001, max_degree=3, model='gcn', standard_split='True', weight_decay=0.0, with_psuedo_loss='False')
(169343, 40)
(169343, 169343)
(169343, 128)
adj: (169343, 169343)
features: (169343, 128)
y: (169343, 40) (169343, 40) (169343, 40)
mask: (169343,) (169343,) (169343,)
x : tensor([[-0.0151, -0.0137, -0.0189,  ...,  0.0451, -0.0450, -0.0365],
        [-0.0580, -0.0329, -0.1515,  ...,  0.0319, -0.1733, -0.1402],
        [-0.0221, -0.0064, -0.0505,  ...,  0.0302,  0.0323, -0.0385],
        ...,
        [-0.0747, -0.0124, -0.1362,  ...,  0.0384, -0.0547, -0.0492],
        [-0.0492,  0.0146, -0.0896,  ..., -0.0318, -0.0147, -0.1339],
        [-0.0113,  0.1018, -0.0611,  ...,  0.0458,  0.0294, -0.0345]],
       device='cuda:0')
sp: tensor(indices=tensor([[     0,      1,      0,  ...,  75409, 138515, 169342],
                       [     0,      0,      1,  ..., 169342, 169342, 169342]]),
       values=tensor([0.5000, 0.3536, 0.3536,  ..., 0.0259, 0.0808, 0.0588]),
       device='cuda:0', size=(169343, 169343), nnz=2484941,
       layout=torch.sparse_coo)
input dim: 128
output dim: 40
num_features_nonzero: 0
Training epoch=0 train loss=20046.03515625 train acc=0.01925424113869667
test acc: 0.006995453033596277
Training epoch=10 train loss=16163.9296875 train acc=0.03687005862593651
test acc: 0.035038989037275314
Training epoch=20 train loss=13441.9453125 train acc=0.06052275374531746
test acc: 0.061025042086839676
Training epoch=30 train loss=17250.01953125 train acc=0.06873687356710434
test acc: 0.0703660324215889
Training epoch=40 train loss=14011.5205078125 train acc=0.048229072242975235
test acc: 0.0571158193051815
Training epoch=50 train loss=13095.380859375 train acc=0.05802663043141365
test acc: 0.049276791512966156
Training epoch=60 train loss=12010.72265625 train acc=0.06276597082614899
test acc: 0.04283686727285385
Training epoch=70 train loss=11044.4873046875 train acc=0.05357319489121437
test acc: 0.04277513921260834
Training epoch=80 train loss=9974.595703125 train acc=0.047877196222543716
test acc: 0.04390675574541092
Training epoch=90 train loss=9450.4306640625 train acc=0.05812560021877289
test acc: 0.044338829815387726
Training epoch=100 train loss=9769.9541015625 train acc=0.041730355471372604
test acc: 0.04518239572644234
Training epoch=110 train loss=7963.9775390625 train acc=0.0643274188041687
test acc: 0.03647923097014427
Training epoch=120 train loss=7520.9658203125 train acc=0.048042137175798416
test acc: 0.03189103677868843
Training epoch=130 train loss=6125.62548828125 train acc=0.042027249932289124
test acc: 0.02409316413104534
Training epoch=140 train loss=5361.80517578125 train acc=0.05072519928216934
test acc: 0.0211098063737154
Training epoch=150 train loss=5177.71875 train acc=0.037617798894643784
test acc: 0.020924635231494904
Training epoch=160 train loss=5825.16162109375 train acc=0.03878339007496834
test acc: 0.02014279179275036
Training epoch=170 train loss=4089.084228515625 train acc=0.031295016407966614
test acc: 0.019196344539523125
Training epoch=180 train loss=4289.009765625 train acc=0.027204452082514763
test acc: 0.0187025498598814
Training epoch=190 train loss=2749.856689453125 train acc=0.03630925714969635
test acc: 0.0184968002140522
Training epoch=200 train loss=3083.5615234375 train acc=0.022575076669454575
test acc: 0.018435075879096985
Training epoch=210 train loss=2554.62890625 train acc=0.024268481880426407
test acc: 0.018393926322460175
Training epoch=220 train loss=1857.79296875 train acc=0.024147523567080498
test acc: 0.018393926322460175
Training epoch=230 train loss=1556.1375732421875 train acc=0.020958643406629562
test acc: 0.018352776765823364
Training epoch=240 train loss=2054.715087890625 train acc=0.020243894308805466
test acc: 0.01837335154414177
Training epoch=250 train loss=1698.01220703125 train acc=0.019914012402296066
test acc: 0.01837335154414177
Training epoch=260 train loss=1533.4918212890625 train acc=0.019815044477581978
test acc: 0.01837335154414177
Training epoch=270 train loss=1515.5185546875 train acc=0.01949615590274334
test acc: 0.018352776765823364
Training epoch=280 train loss=1302.9237060546875 train acc=0.018605470657348633
test acc: 0.018352776765823364
Training epoch=290 train loss=1598.838134765625 train acc=0.018429532647132874
test acc: 0.018352776765823364
Training epoch=300 train loss=1109.285888671875 train acc=0.017967693507671356
test acc: 0.018352776765823364
Training epoch=310 train loss=1154.7347412109375 train acc=0.018418535590171814
test acc: 0.018352776765823364
Training epoch=320 train loss=1276.6610107421875 train acc=0.017582830041646957
test acc: 0.018352776765823364
Training epoch=330 train loss=1667.7474365234375 train acc=0.017725778743624687
test acc: 0.018352776765823364
Training epoch=340 train loss=1022.2053833007812 train acc=0.01721995510160923
test acc: 0.018352776765823364
Training epoch=350 train loss=1043.9451904296875 train acc=0.01709899678826332
test acc: 0.018352776765823364
Training epoch=360 train loss=524.2611083984375 train acc=0.01723095029592514
test acc: 0.018352776765823364
Training epoch=370 train loss=1200.01318359375 train acc=0.01713198609650135
test acc: 0.018352776765823364
Training epoch=380 train loss=1028.7113037109375 train acc=0.016725128516554832
test acc: 0.018352776765823364
Training epoch=390 train loss=997.7794799804688 train acc=0.016604172065854073
test acc: 0.018352776765823364
Training epoch=400 train loss=1138.5433349609375 train acc=0.016527198255062103
test acc: 0.018352776765823364
Training epoch=410 train loss=439.981201171875 train acc=0.016307277604937553
test acc: 0.018352776765823364
Training epoch=420 train loss=384.5028381347656 train acc=0.016010379418730736
test acc: 0.018352776765823364
Training epoch=430 train loss=1098.0645751953125 train acc=0.016131337732076645
test acc: 0.018352776765823364
Training epoch=440 train loss=850.0972290039062 train acc=0.016087353229522705
test acc: 0.018352776765823364
Training epoch=450 train loss=582.59130859375 train acc=0.015911415219306946
test acc: 0.018352776765823364
Training epoch=460 train loss=413.7496032714844 train acc=0.015955399721860886
test acc: 0.018352776765823364
Training epoch=470 train loss=339.73150634765625 train acc=0.015757469460368156
test acc: 0.018352776765823364
Training epoch=480 train loss=554.0471801757812 train acc=0.015735475346446037
test acc: 0.018352776765823364
Training epoch=490 train loss=684.1243896484375 train acc=0.015812451019883156
test acc: 0.018352776765823364
Training epoch=500 train loss=369.25408935546875 train acc=0.015614519827067852
test acc: 0.018352776765823364
Training epoch=510 train loss=477.6162109375 train acc=0.015702487900853157
test acc: 0.018352776765823364
Training epoch=520 train loss=431.3470458984375 train acc=0.016109345480799675
test acc: 0.018352776765823364
Training epoch=530 train loss=211.6956024169922 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=540 train loss=666.2645874023438 train acc=0.015625515952706337
test acc: 0.018352776765823364
Training epoch=550 train loss=315.9358215332031 train acc=0.015504557639360428
test acc: 0.018352776765823364
Training epoch=560 train loss=264.5771789550781 train acc=0.015449577011168003
test acc: 0.018352776765823364
Training epoch=570 train loss=226.6393280029297 train acc=0.015350611880421638
test acc: 0.018352776765823364
Training epoch=580 train loss=154.70286560058594 train acc=0.015504558570683002
test acc: 0.018352776765823364
Training epoch=590 train loss=297.6166687011719 train acc=0.015251646749675274
test acc: 0.018352776765823364
Training epoch=600 train loss=149.0151824951172 train acc=0.015449577011168003
test acc: 0.018352776765823364
Training epoch=610 train loss=314.4405212402344 train acc=0.015361608006060123
test acc: 0.018352776765823364
Training epoch=620 train loss=153.7670135498047 train acc=0.015317622572183609
test acc: 0.018352776765823364
Training epoch=630 train loss=172.78549194335938 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=640 train loss=97.95993041992188 train acc=0.015163677744567394
test acc: 0.018352776765823364
Training epoch=650 train loss=107.60059356689453 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=660 train loss=122.03556060791016 train acc=0.015460572205483913
test acc: 0.018352776765823364
Training epoch=670 train loss=634.636962890625 train acc=0.01510869525372982
test acc: 0.018352776765823364
Training epoch=680 train loss=108.26631927490234 train acc=0.015196666121482849
test acc: 0.018352776765823364
Training epoch=690 train loss=104.51615905761719 train acc=0.015163675881922245
test acc: 0.018352776765823364
Training epoch=700 train loss=115.58907318115234 train acc=0.015163675881922245
test acc: 0.018352776765823364
Training epoch=710 train loss=369.38873291015625 train acc=0.015174674801528454
test acc: 0.018352776765823364
Training epoch=720 train loss=91.96066284179688 train acc=0.01505371555685997
test acc: 0.018352776765823364
Training epoch=730 train loss=95.36050415039062 train acc=0.015218658372759819
test acc: 0.018352776765823364
Training epoch=740 train loss=105.92737579345703 train acc=0.015317624434828758
test acc: 0.018352776765823364
Training epoch=750 train loss=59.12226867675781 train acc=0.015141686424612999
test acc: 0.018352776765823364
Training epoch=760 train loss=117.86026000976562 train acc=0.01515268161892891
test acc: 0.018352776765823364
Training epoch=770 train loss=291.3061218261719 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=780 train loss=159.56521606445312 train acc=0.01506471261382103
test acc: 0.018352776765823364
Training epoch=790 train loss=86.24385833740234 train acc=0.01514168456196785
test acc: 0.018352776765823364
Training epoch=800 train loss=416.1731262207031 train acc=0.015075708739459515
test acc: 0.018352776765823364
Training epoch=810 train loss=208.1509552001953 train acc=0.015130690298974514
test acc: 0.018352776765823364
Training epoch=820 train loss=66.58364868164062 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=830 train loss=186.26687622070312 train acc=0.015031723305583
test acc: 0.018352776765823364
Training epoch=840 train loss=257.361572265625 train acc=0.01506471261382103
test acc: 0.018352776765823364
Training epoch=850 train loss=66.5474853515625 train acc=0.015130688436329365
test acc: 0.018352776765823364
Training epoch=860 train loss=219.64268493652344 train acc=0.01507570967078209
test acc: 0.018352776765823364
Training epoch=870 train loss=81.72249603271484 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=880 train loss=115.5125732421875 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=890 train loss=968.2783203125 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=900 train loss=50.06705856323242 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=910 train loss=501.2398986816406 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=920 train loss=40.806785583496094 train acc=0.015042721293866634
test acc: 0.018352776765823364
Training epoch=930 train loss=38.38389587402344 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=940 train loss=51.19314193725586 train acc=0.014888773672282696
test acc: 0.018352776765823364
Training epoch=950 train loss=282.293212890625 train acc=0.01498774066567421
test acc: 0.018352776765823364
Training epoch=960 train loss=348.9414978027344 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=970 train loss=63.99274444580078 train acc=0.01493275910615921
test acc: 0.018352776765823364
Training epoch=980 train loss=50.42446517944336 train acc=0.014921761117875576
test acc: 0.018352776765823364
Training epoch=990 train loss=171.4427032470703 train acc=0.01494375430047512
test acc: 0.018352776765823364
Namespace(confidence_threshold=0.75, dataset='ogbn-arxiv', dropout=0.5, early_stopping=10, epochs=1000, exp_id='arxiv_std_gcn_0', exp_times='6', feature_normalize='True', few_label_number=10, few_label_seed=6, hidden_list='[256,256,256]', learning_rate=0.001, max_degree=3, model='gcn', standard_split='True', weight_decay=0.0, with_psuedo_loss='False')
(169343, 40)
(169343, 169343)
(169343, 128)
adj: (169343, 169343)
features: (169343, 128)
y: (169343, 40) (169343, 40) (169343, 40)
mask: (169343,) (169343,) (169343,)
x : tensor([[-0.0151, -0.0137, -0.0189,  ...,  0.0451, -0.0450, -0.0365],
        [-0.0580, -0.0329, -0.1515,  ...,  0.0319, -0.1733, -0.1402],
        [-0.0221, -0.0064, -0.0505,  ...,  0.0302,  0.0323, -0.0385],
        ...,
        [-0.0747, -0.0124, -0.1362,  ...,  0.0384, -0.0547, -0.0492],
        [-0.0492,  0.0146, -0.0896,  ..., -0.0318, -0.0147, -0.1339],
        [-0.0113,  0.1018, -0.0611,  ...,  0.0458,  0.0294, -0.0345]],
       device='cuda:0')
sp: tensor(indices=tensor([[     0,      1,      0,  ...,  75409, 138515, 169342],
                       [     0,      0,      1,  ..., 169342, 169342, 169342]]),
       values=tensor([0.5000, 0.3536, 0.3536,  ..., 0.0259, 0.0808, 0.0588]),
       device='cuda:0', size=(169343, 169343), nnz=2484941,
       layout=torch.sparse_coo)
input dim: 128
output dim: 40
num_features_nonzero: 0
Training epoch=0 train loss=20046.03515625 train acc=0.01925424113869667
test acc: 0.006995453033596277
Training epoch=10 train loss=16163.9296875 train acc=0.03687005862593651
test acc: 0.035038989037275314
Training epoch=20 train loss=13441.9453125 train acc=0.06052275374531746
test acc: 0.061025042086839676
Training epoch=30 train loss=17250.01953125 train acc=0.06873687356710434
test acc: 0.0703660324215889
Training epoch=40 train loss=14011.5205078125 train acc=0.048229072242975235
test acc: 0.0571158193051815
Training epoch=50 train loss=13095.380859375 train acc=0.05802663043141365
test acc: 0.049276791512966156
Training epoch=60 train loss=12010.72265625 train acc=0.06276597082614899
test acc: 0.04283686727285385
Training epoch=70 train loss=11044.4873046875 train acc=0.05357319489121437
test acc: 0.04277513921260834
Training epoch=80 train loss=9974.595703125 train acc=0.047877196222543716
test acc: 0.04390675574541092
Training epoch=90 train loss=9450.4306640625 train acc=0.05812560021877289
test acc: 0.044338829815387726
Training epoch=100 train loss=9769.9541015625 train acc=0.041730355471372604
test acc: 0.04518239572644234
Training epoch=110 train loss=7963.9775390625 train acc=0.0643274188041687
test acc: 0.03647923097014427
Training epoch=120 train loss=7520.9658203125 train acc=0.048042137175798416
test acc: 0.03189103677868843
Training epoch=130 train loss=6125.62548828125 train acc=0.042027249932289124
test acc: 0.02409316413104534
Training epoch=140 train loss=5361.80517578125 train acc=0.05072519928216934
test acc: 0.0211098063737154
Training epoch=150 train loss=5177.71875 train acc=0.037617798894643784
test acc: 0.020924635231494904
Training epoch=160 train loss=5825.16162109375 train acc=0.03878339007496834
test acc: 0.02014279179275036
Training epoch=170 train loss=4089.084228515625 train acc=0.031295016407966614
test acc: 0.019196344539523125
Training epoch=180 train loss=4289.009765625 train acc=0.027204452082514763
test acc: 0.0187025498598814
Training epoch=190 train loss=2749.856689453125 train acc=0.03630925714969635
test acc: 0.0184968002140522
Training epoch=200 train loss=3083.5615234375 train acc=0.022575076669454575
test acc: 0.018435075879096985
Training epoch=210 train loss=2554.62890625 train acc=0.024268481880426407
test acc: 0.018393926322460175
Training epoch=220 train loss=1857.79296875 train acc=0.024147523567080498
test acc: 0.018393926322460175
Training epoch=230 train loss=1556.1375732421875 train acc=0.020958643406629562
test acc: 0.018352776765823364
Training epoch=240 train loss=2054.715087890625 train acc=0.020243894308805466
test acc: 0.01837335154414177
Training epoch=250 train loss=1698.01220703125 train acc=0.019914012402296066
test acc: 0.01837335154414177
Training epoch=260 train loss=1533.4918212890625 train acc=0.019815044477581978
test acc: 0.01837335154414177
Training epoch=270 train loss=1515.5185546875 train acc=0.01949615590274334
test acc: 0.018352776765823364
Training epoch=280 train loss=1302.9237060546875 train acc=0.018605470657348633
test acc: 0.018352776765823364
Training epoch=290 train loss=1598.838134765625 train acc=0.018429532647132874
test acc: 0.018352776765823364
Training epoch=300 train loss=1109.285888671875 train acc=0.017967693507671356
test acc: 0.018352776765823364
Training epoch=310 train loss=1154.7347412109375 train acc=0.018418535590171814
test acc: 0.018352776765823364
Training epoch=320 train loss=1276.6610107421875 train acc=0.017582830041646957
test acc: 0.018352776765823364
Training epoch=330 train loss=1667.7474365234375 train acc=0.017725778743624687
test acc: 0.018352776765823364
Training epoch=340 train loss=1022.2053833007812 train acc=0.01721995510160923
test acc: 0.018352776765823364
Training epoch=350 train loss=1043.9451904296875 train acc=0.01709899678826332
test acc: 0.018352776765823364
Training epoch=360 train loss=524.2611083984375 train acc=0.01723095029592514
test acc: 0.018352776765823364
Training epoch=370 train loss=1200.01318359375 train acc=0.01713198609650135
test acc: 0.018352776765823364
Training epoch=380 train loss=1028.7113037109375 train acc=0.016725128516554832
test acc: 0.018352776765823364
Training epoch=390 train loss=997.7794799804688 train acc=0.016604172065854073
test acc: 0.018352776765823364
Training epoch=400 train loss=1138.5433349609375 train acc=0.016527198255062103
test acc: 0.018352776765823364
Training epoch=410 train loss=439.981201171875 train acc=0.016307277604937553
test acc: 0.018352776765823364
Training epoch=420 train loss=384.5028381347656 train acc=0.016010379418730736
test acc: 0.018352776765823364
Training epoch=430 train loss=1098.0645751953125 train acc=0.016131337732076645
test acc: 0.018352776765823364
Training epoch=440 train loss=850.0972290039062 train acc=0.016087353229522705
test acc: 0.018352776765823364
Training epoch=450 train loss=582.59130859375 train acc=0.015911415219306946
test acc: 0.018352776765823364
Training epoch=460 train loss=413.7496032714844 train acc=0.015955399721860886
test acc: 0.018352776765823364
Training epoch=470 train loss=339.73150634765625 train acc=0.015757469460368156
test acc: 0.018352776765823364
Training epoch=480 train loss=554.0471801757812 train acc=0.015735475346446037
test acc: 0.018352776765823364
Training epoch=490 train loss=684.1243896484375 train acc=0.015812451019883156
test acc: 0.018352776765823364
Training epoch=500 train loss=369.25408935546875 train acc=0.015614519827067852
test acc: 0.018352776765823364
Training epoch=510 train loss=477.6162109375 train acc=0.015702487900853157
test acc: 0.018352776765823364
Training epoch=520 train loss=431.3470458984375 train acc=0.016109345480799675
test acc: 0.018352776765823364
Training epoch=530 train loss=211.6956024169922 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=540 train loss=666.2645874023438 train acc=0.015625515952706337
test acc: 0.018352776765823364
Training epoch=550 train loss=315.9358215332031 train acc=0.015504557639360428
test acc: 0.018352776765823364
Training epoch=560 train loss=264.5771789550781 train acc=0.015449577011168003
test acc: 0.018352776765823364
Training epoch=570 train loss=226.6393280029297 train acc=0.015350611880421638
test acc: 0.018352776765823364
Training epoch=580 train loss=154.70286560058594 train acc=0.015504558570683002
test acc: 0.018352776765823364
Training epoch=590 train loss=297.6166687011719 train acc=0.015251646749675274
test acc: 0.018352776765823364
Training epoch=600 train loss=149.0151824951172 train acc=0.015449577011168003
test acc: 0.018352776765823364
Training epoch=610 train loss=314.4405212402344 train acc=0.015361608006060123
test acc: 0.018352776765823364
Training epoch=620 train loss=153.7670135498047 train acc=0.015317622572183609
test acc: 0.018352776765823364
Training epoch=630 train loss=172.78549194335938 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=640 train loss=97.95993041992188 train acc=0.015163677744567394
test acc: 0.018352776765823364
Training epoch=650 train loss=107.60059356689453 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=660 train loss=122.03556060791016 train acc=0.015460572205483913
test acc: 0.018352776765823364
Training epoch=670 train loss=634.636962890625 train acc=0.01510869525372982
test acc: 0.018352776765823364
Training epoch=680 train loss=108.26631927490234 train acc=0.015196666121482849
test acc: 0.018352776765823364
Training epoch=690 train loss=104.51615905761719 train acc=0.015163675881922245
test acc: 0.018352776765823364
Training epoch=700 train loss=115.58907318115234 train acc=0.015163675881922245
test acc: 0.018352776765823364
Training epoch=710 train loss=369.38873291015625 train acc=0.015174674801528454
test acc: 0.018352776765823364
Training epoch=720 train loss=91.96066284179688 train acc=0.01505371555685997
test acc: 0.018352776765823364
Training epoch=730 train loss=95.36050415039062 train acc=0.015218658372759819
test acc: 0.018352776765823364
Training epoch=740 train loss=105.92737579345703 train acc=0.015317624434828758
test acc: 0.018352776765823364
Training epoch=750 train loss=59.12226867675781 train acc=0.015141686424612999
test acc: 0.018352776765823364
Training epoch=760 train loss=117.86026000976562 train acc=0.01515268161892891
test acc: 0.018352776765823364
Training epoch=770 train loss=291.3061218261719 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=780 train loss=159.56521606445312 train acc=0.01506471261382103
test acc: 0.018352776765823364
Training epoch=790 train loss=86.24385833740234 train acc=0.01514168456196785
test acc: 0.018352776765823364
Training epoch=800 train loss=416.1731262207031 train acc=0.015075708739459515
test acc: 0.018352776765823364
Training epoch=810 train loss=208.1509552001953 train acc=0.015130690298974514
test acc: 0.018352776765823364
Training epoch=820 train loss=66.58364868164062 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=830 train loss=186.26687622070312 train acc=0.015031723305583
test acc: 0.018352776765823364
Training epoch=840 train loss=257.361572265625 train acc=0.01506471261382103
test acc: 0.018352776765823364
Training epoch=850 train loss=66.5474853515625 train acc=0.015130688436329365
test acc: 0.018352776765823364
Training epoch=860 train loss=219.64268493652344 train acc=0.01507570967078209
test acc: 0.018352776765823364
Training epoch=870 train loss=81.72249603271484 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=880 train loss=115.5125732421875 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=890 train loss=968.2783203125 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=900 train loss=50.06705856323242 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=910 train loss=501.2398986816406 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=920 train loss=40.806785583496094 train acc=0.015042721293866634
test acc: 0.018352776765823364
Training epoch=930 train loss=38.38389587402344 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=940 train loss=51.19314193725586 train acc=0.014888773672282696
test acc: 0.018352776765823364
Training epoch=950 train loss=282.293212890625 train acc=0.01498774066567421
test acc: 0.018352776765823364
Training epoch=960 train loss=348.9414978027344 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=970 train loss=63.99274444580078 train acc=0.01493275910615921
test acc: 0.018352776765823364
Training epoch=980 train loss=50.42446517944336 train acc=0.014921761117875576
test acc: 0.018352776765823364
Training epoch=990 train loss=171.4427032470703 train acc=0.01494375430047512
test acc: 0.018352776765823364
Namespace(confidence_threshold=0.75, dataset='ogbn-arxiv', dropout=0.5, early_stopping=10, epochs=1000, exp_id='arxiv_std_gcn_0', exp_times='7', feature_normalize='True', few_label_number=10, few_label_seed=7, hidden_list='[256,256,256]', learning_rate=0.001, max_degree=3, model='gcn', standard_split='True', weight_decay=0.0, with_psuedo_loss='False')
(169343, 40)
(169343, 169343)
(169343, 128)
adj: (169343, 169343)
features: (169343, 128)
y: (169343, 40) (169343, 40) (169343, 40)
mask: (169343,) (169343,) (169343,)
x : tensor([[-0.0151, -0.0137, -0.0189,  ...,  0.0451, -0.0450, -0.0365],
        [-0.0580, -0.0329, -0.1515,  ...,  0.0319, -0.1733, -0.1402],
        [-0.0221, -0.0064, -0.0505,  ...,  0.0302,  0.0323, -0.0385],
        ...,
        [-0.0747, -0.0124, -0.1362,  ...,  0.0384, -0.0547, -0.0492],
        [-0.0492,  0.0146, -0.0896,  ..., -0.0318, -0.0147, -0.1339],
        [-0.0113,  0.1018, -0.0611,  ...,  0.0458,  0.0294, -0.0345]],
       device='cuda:0')
sp: tensor(indices=tensor([[     0,      1,      0,  ...,  75409, 138515, 169342],
                       [     0,      0,      1,  ..., 169342, 169342, 169342]]),
       values=tensor([0.5000, 0.3536, 0.3536,  ..., 0.0259, 0.0808, 0.0588]),
       device='cuda:0', size=(169343, 169343), nnz=2484941,
       layout=torch.sparse_coo)
input dim: 128
output dim: 40
num_features_nonzero: 0
Training epoch=0 train loss=20046.03515625 train acc=0.01925424113869667
test acc: 0.006995453033596277
Training epoch=10 train loss=16163.9296875 train acc=0.03687005862593651
test acc: 0.035038989037275314
Training epoch=20 train loss=13441.9453125 train acc=0.06052275374531746
test acc: 0.061025042086839676
Training epoch=30 train loss=17250.01953125 train acc=0.06873687356710434
test acc: 0.0703660324215889
Training epoch=40 train loss=14011.5205078125 train acc=0.048229072242975235
test acc: 0.0571158193051815
Training epoch=50 train loss=13095.380859375 train acc=0.05802663043141365
test acc: 0.049276791512966156
Training epoch=60 train loss=12010.72265625 train acc=0.06276597082614899
test acc: 0.04283686727285385
Training epoch=70 train loss=11044.4873046875 train acc=0.05357319489121437
test acc: 0.04277513921260834
Training epoch=80 train loss=9974.595703125 train acc=0.047877196222543716
test acc: 0.04390675574541092
Training epoch=90 train loss=9450.4306640625 train acc=0.05812560021877289
test acc: 0.044338829815387726
Training epoch=100 train loss=9769.9541015625 train acc=0.041730355471372604
test acc: 0.04518239572644234
Training epoch=110 train loss=7963.9775390625 train acc=0.0643274188041687
test acc: 0.03647923097014427
Training epoch=120 train loss=7520.9658203125 train acc=0.048042137175798416
test acc: 0.03189103677868843
Training epoch=130 train loss=6125.62548828125 train acc=0.042027249932289124
test acc: 0.02409316413104534
Training epoch=140 train loss=5361.80517578125 train acc=0.05072519928216934
test acc: 0.0211098063737154
Training epoch=150 train loss=5177.71875 train acc=0.037617798894643784
test acc: 0.020924635231494904
Training epoch=160 train loss=5825.16162109375 train acc=0.03878339007496834
test acc: 0.02014279179275036
Training epoch=170 train loss=4089.084228515625 train acc=0.031295016407966614
test acc: 0.019196344539523125
Training epoch=180 train loss=4289.009765625 train acc=0.027204452082514763
test acc: 0.0187025498598814
Training epoch=190 train loss=2749.856689453125 train acc=0.03630925714969635
test acc: 0.0184968002140522
Training epoch=200 train loss=3083.5615234375 train acc=0.022575076669454575
test acc: 0.018435075879096985
Training epoch=210 train loss=2554.62890625 train acc=0.024268481880426407
test acc: 0.018393926322460175
Training epoch=220 train loss=1857.79296875 train acc=0.024147523567080498
test acc: 0.018393926322460175
Training epoch=230 train loss=1556.1375732421875 train acc=0.020958643406629562
test acc: 0.018352776765823364
Training epoch=240 train loss=2054.715087890625 train acc=0.020243894308805466
test acc: 0.01837335154414177
Training epoch=250 train loss=1698.01220703125 train acc=0.019914012402296066
test acc: 0.01837335154414177
Training epoch=260 train loss=1533.4918212890625 train acc=0.019815044477581978
test acc: 0.01837335154414177
Training epoch=270 train loss=1515.5185546875 train acc=0.01949615590274334
test acc: 0.018352776765823364
Training epoch=280 train loss=1302.9237060546875 train acc=0.018605470657348633
test acc: 0.018352776765823364
Training epoch=290 train loss=1598.838134765625 train acc=0.018429532647132874
test acc: 0.018352776765823364
Training epoch=300 train loss=1109.285888671875 train acc=0.017967693507671356
test acc: 0.018352776765823364
Training epoch=310 train loss=1154.7347412109375 train acc=0.018418535590171814
test acc: 0.018352776765823364
Training epoch=320 train loss=1276.6610107421875 train acc=0.017582830041646957
test acc: 0.018352776765823364
Training epoch=330 train loss=1667.7474365234375 train acc=0.017725778743624687
test acc: 0.018352776765823364
Training epoch=340 train loss=1022.2053833007812 train acc=0.01721995510160923
test acc: 0.018352776765823364
Training epoch=350 train loss=1043.9451904296875 train acc=0.01709899678826332
test acc: 0.018352776765823364
Training epoch=360 train loss=524.2611083984375 train acc=0.01723095029592514
test acc: 0.018352776765823364
Training epoch=370 train loss=1200.01318359375 train acc=0.01713198609650135
test acc: 0.018352776765823364
Training epoch=380 train loss=1028.7113037109375 train acc=0.016725128516554832
test acc: 0.018352776765823364
Training epoch=390 train loss=997.7794799804688 train acc=0.016604172065854073
test acc: 0.018352776765823364
Training epoch=400 train loss=1138.5433349609375 train acc=0.016527198255062103
test acc: 0.018352776765823364
Training epoch=410 train loss=439.981201171875 train acc=0.016307277604937553
test acc: 0.018352776765823364
Training epoch=420 train loss=384.5028381347656 train acc=0.016010379418730736
test acc: 0.018352776765823364
Training epoch=430 train loss=1098.0645751953125 train acc=0.016131337732076645
test acc: 0.018352776765823364
Training epoch=440 train loss=850.0972290039062 train acc=0.016087353229522705
test acc: 0.018352776765823364
Training epoch=450 train loss=582.59130859375 train acc=0.015911415219306946
test acc: 0.018352776765823364
Training epoch=460 train loss=413.7496032714844 train acc=0.015955399721860886
test acc: 0.018352776765823364
Training epoch=470 train loss=339.73150634765625 train acc=0.015757469460368156
test acc: 0.018352776765823364
Training epoch=480 train loss=554.0471801757812 train acc=0.015735475346446037
test acc: 0.018352776765823364
Training epoch=490 train loss=684.1243896484375 train acc=0.015812451019883156
test acc: 0.018352776765823364
Training epoch=500 train loss=369.25408935546875 train acc=0.015614519827067852
test acc: 0.018352776765823364
Training epoch=510 train loss=477.6162109375 train acc=0.015702487900853157
test acc: 0.018352776765823364
Training epoch=520 train loss=431.3470458984375 train acc=0.016109345480799675
test acc: 0.018352776765823364
Training epoch=530 train loss=211.6956024169922 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=540 train loss=666.2645874023438 train acc=0.015625515952706337
test acc: 0.018352776765823364
Training epoch=550 train loss=315.9358215332031 train acc=0.015504557639360428
test acc: 0.018352776765823364
Training epoch=560 train loss=264.5771789550781 train acc=0.015449577011168003
test acc: 0.018352776765823364
Training epoch=570 train loss=226.6393280029297 train acc=0.015350611880421638
test acc: 0.018352776765823364
Training epoch=580 train loss=154.70286560058594 train acc=0.015504558570683002
test acc: 0.018352776765823364
Training epoch=590 train loss=297.6166687011719 train acc=0.015251646749675274
test acc: 0.018352776765823364
Training epoch=600 train loss=149.0151824951172 train acc=0.015449577011168003
test acc: 0.018352776765823364
Training epoch=610 train loss=314.4405212402344 train acc=0.015361608006060123
test acc: 0.018352776765823364
Training epoch=620 train loss=153.7670135498047 train acc=0.015317622572183609
test acc: 0.018352776765823364
Training epoch=630 train loss=172.78549194335938 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=640 train loss=97.95993041992188 train acc=0.015163677744567394
test acc: 0.018352776765823364
Training epoch=650 train loss=107.60059356689453 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=660 train loss=122.03556060791016 train acc=0.015460572205483913
test acc: 0.018352776765823364
Training epoch=670 train loss=634.636962890625 train acc=0.01510869525372982
test acc: 0.018352776765823364
Training epoch=680 train loss=108.26631927490234 train acc=0.015196666121482849
test acc: 0.018352776765823364
Training epoch=690 train loss=104.51615905761719 train acc=0.015163675881922245
test acc: 0.018352776765823364
Training epoch=700 train loss=115.58907318115234 train acc=0.015163675881922245
test acc: 0.018352776765823364
Training epoch=710 train loss=369.38873291015625 train acc=0.015174674801528454
test acc: 0.018352776765823364
Training epoch=720 train loss=91.96066284179688 train acc=0.01505371555685997
test acc: 0.018352776765823364
Training epoch=730 train loss=95.36050415039062 train acc=0.015218658372759819
test acc: 0.018352776765823364
Training epoch=740 train loss=105.92737579345703 train acc=0.015317624434828758
test acc: 0.018352776765823364
Training epoch=750 train loss=59.12226867675781 train acc=0.015141686424612999
test acc: 0.018352776765823364
Training epoch=760 train loss=117.86026000976562 train acc=0.01515268161892891
test acc: 0.018352776765823364
Training epoch=770 train loss=291.3061218261719 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=780 train loss=159.56521606445312 train acc=0.01506471261382103
test acc: 0.018352776765823364
Training epoch=790 train loss=86.24385833740234 train acc=0.01514168456196785
test acc: 0.018352776765823364
Training epoch=800 train loss=416.1731262207031 train acc=0.015075708739459515
test acc: 0.018352776765823364
Training epoch=810 train loss=208.1509552001953 train acc=0.015130690298974514
test acc: 0.018352776765823364
Training epoch=820 train loss=66.58364868164062 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=830 train loss=186.26687622070312 train acc=0.015031723305583
test acc: 0.018352776765823364
Training epoch=840 train loss=257.361572265625 train acc=0.01506471261382103
test acc: 0.018352776765823364
Training epoch=850 train loss=66.5474853515625 train acc=0.015130688436329365
test acc: 0.018352776765823364
Training epoch=860 train loss=219.64268493652344 train acc=0.01507570967078209
test acc: 0.018352776765823364
Training epoch=870 train loss=81.72249603271484 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=880 train loss=115.5125732421875 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=890 train loss=968.2783203125 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=900 train loss=50.06705856323242 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=910 train loss=501.2398986816406 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=920 train loss=40.806785583496094 train acc=0.015042721293866634
test acc: 0.018352776765823364
Training epoch=930 train loss=38.38389587402344 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=940 train loss=51.19314193725586 train acc=0.014888773672282696
test acc: 0.018352776765823364
Training epoch=950 train loss=282.293212890625 train acc=0.01498774066567421
test acc: 0.018352776765823364
Training epoch=960 train loss=348.9414978027344 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=970 train loss=63.99274444580078 train acc=0.01493275910615921
test acc: 0.018352776765823364
Training epoch=980 train loss=50.42446517944336 train acc=0.014921761117875576
test acc: 0.018352776765823364
Training epoch=990 train loss=171.4427032470703 train acc=0.01494375430047512
test acc: 0.018352776765823364
Namespace(confidence_threshold=0.75, dataset='ogbn-arxiv', dropout=0.5, early_stopping=10, epochs=1000, exp_id='arxiv_std_gcn_0', exp_times='8', feature_normalize='True', few_label_number=10, few_label_seed=8, hidden_list='[256,256,256]', learning_rate=0.001, max_degree=3, model='gcn', standard_split='True', weight_decay=0.0, with_psuedo_loss='False')
(169343, 40)
(169343, 169343)
(169343, 128)
adj: (169343, 169343)
features: (169343, 128)
y: (169343, 40) (169343, 40) (169343, 40)
mask: (169343,) (169343,) (169343,)
x : tensor([[-0.0151, -0.0137, -0.0189,  ...,  0.0451, -0.0450, -0.0365],
        [-0.0580, -0.0329, -0.1515,  ...,  0.0319, -0.1733, -0.1402],
        [-0.0221, -0.0064, -0.0505,  ...,  0.0302,  0.0323, -0.0385],
        ...,
        [-0.0747, -0.0124, -0.1362,  ...,  0.0384, -0.0547, -0.0492],
        [-0.0492,  0.0146, -0.0896,  ..., -0.0318, -0.0147, -0.1339],
        [-0.0113,  0.1018, -0.0611,  ...,  0.0458,  0.0294, -0.0345]],
       device='cuda:0')
sp: tensor(indices=tensor([[     0,      1,      0,  ...,  75409, 138515, 169342],
                       [     0,      0,      1,  ..., 169342, 169342, 169342]]),
       values=tensor([0.5000, 0.3536, 0.3536,  ..., 0.0259, 0.0808, 0.0588]),
       device='cuda:0', size=(169343, 169343), nnz=2484941,
       layout=torch.sparse_coo)
input dim: 128
output dim: 40
num_features_nonzero: 0
Training epoch=0 train loss=20046.03515625 train acc=0.01925424113869667
test acc: 0.006995453033596277
Training epoch=10 train loss=16163.9296875 train acc=0.03687005862593651
test acc: 0.035038989037275314
Training epoch=20 train loss=13441.9453125 train acc=0.06052275374531746
test acc: 0.061025042086839676
Training epoch=30 train loss=17250.01953125 train acc=0.06873687356710434
test acc: 0.0703660324215889
Training epoch=40 train loss=14011.5205078125 train acc=0.048229072242975235
test acc: 0.0571158193051815
Training epoch=50 train loss=13095.380859375 train acc=0.05802663043141365
test acc: 0.049276791512966156
Training epoch=60 train loss=12010.72265625 train acc=0.06276597082614899
test acc: 0.04283686727285385
Training epoch=70 train loss=11044.4873046875 train acc=0.05357319489121437
test acc: 0.04277513921260834
Training epoch=80 train loss=9974.595703125 train acc=0.047877196222543716
test acc: 0.04390675574541092
Training epoch=90 train loss=9450.4306640625 train acc=0.05812560021877289
test acc: 0.044338829815387726
Training epoch=100 train loss=9769.9541015625 train acc=0.041730355471372604
test acc: 0.04518239572644234
Training epoch=110 train loss=7963.9775390625 train acc=0.0643274188041687
test acc: 0.03647923097014427
Training epoch=120 train loss=7520.9658203125 train acc=0.048042137175798416
test acc: 0.03189103677868843
Training epoch=130 train loss=6125.62548828125 train acc=0.042027249932289124
test acc: 0.02409316413104534
Training epoch=140 train loss=5361.80517578125 train acc=0.05072519928216934
test acc: 0.0211098063737154
Training epoch=150 train loss=5177.71875 train acc=0.037617798894643784
test acc: 0.020924635231494904
Training epoch=160 train loss=5825.16162109375 train acc=0.03878339007496834
test acc: 0.02014279179275036
Training epoch=170 train loss=4089.084228515625 train acc=0.031295016407966614
test acc: 0.019196344539523125
Training epoch=180 train loss=4289.009765625 train acc=0.027204452082514763
test acc: 0.0187025498598814
Training epoch=190 train loss=2749.856689453125 train acc=0.03630925714969635
test acc: 0.0184968002140522
Training epoch=200 train loss=3083.5615234375 train acc=0.022575076669454575
test acc: 0.018435075879096985
Training epoch=210 train loss=2554.62890625 train acc=0.024268481880426407
test acc: 0.018393926322460175
Training epoch=220 train loss=1857.79296875 train acc=0.024147523567080498
test acc: 0.018393926322460175
Training epoch=230 train loss=1556.1375732421875 train acc=0.020958643406629562
test acc: 0.018352776765823364
Training epoch=240 train loss=2054.715087890625 train acc=0.020243894308805466
test acc: 0.01837335154414177
Training epoch=250 train loss=1698.01220703125 train acc=0.019914012402296066
test acc: 0.01837335154414177
Training epoch=260 train loss=1533.4918212890625 train acc=0.019815044477581978
test acc: 0.01837335154414177
Training epoch=270 train loss=1515.5185546875 train acc=0.01949615590274334
test acc: 0.018352776765823364
Training epoch=280 train loss=1302.9237060546875 train acc=0.018605470657348633
test acc: 0.018352776765823364
Training epoch=290 train loss=1598.838134765625 train acc=0.018429532647132874
test acc: 0.018352776765823364
Training epoch=300 train loss=1109.285888671875 train acc=0.017967693507671356
test acc: 0.018352776765823364
Training epoch=310 train loss=1154.7347412109375 train acc=0.018418535590171814
test acc: 0.018352776765823364
Training epoch=320 train loss=1276.6610107421875 train acc=0.017582830041646957
test acc: 0.018352776765823364
Training epoch=330 train loss=1667.7474365234375 train acc=0.017725778743624687
test acc: 0.018352776765823364
Training epoch=340 train loss=1022.2053833007812 train acc=0.01721995510160923
test acc: 0.018352776765823364
Training epoch=350 train loss=1043.9451904296875 train acc=0.01709899678826332
test acc: 0.018352776765823364
Training epoch=360 train loss=524.2611083984375 train acc=0.01723095029592514
test acc: 0.018352776765823364
Training epoch=370 train loss=1200.01318359375 train acc=0.01713198609650135
test acc: 0.018352776765823364
Training epoch=380 train loss=1028.7113037109375 train acc=0.016725128516554832
test acc: 0.018352776765823364
Training epoch=390 train loss=997.7794799804688 train acc=0.016604172065854073
test acc: 0.018352776765823364
Training epoch=400 train loss=1138.5433349609375 train acc=0.016527198255062103
test acc: 0.018352776765823364
Training epoch=410 train loss=439.981201171875 train acc=0.016307277604937553
test acc: 0.018352776765823364
Training epoch=420 train loss=384.5028381347656 train acc=0.016010379418730736
test acc: 0.018352776765823364
Training epoch=430 train loss=1098.0645751953125 train acc=0.016131337732076645
test acc: 0.018352776765823364
Training epoch=440 train loss=850.0972290039062 train acc=0.016087353229522705
test acc: 0.018352776765823364
Training epoch=450 train loss=582.59130859375 train acc=0.015911415219306946
test acc: 0.018352776765823364
Training epoch=460 train loss=413.7496032714844 train acc=0.015955399721860886
test acc: 0.018352776765823364
Training epoch=470 train loss=339.73150634765625 train acc=0.015757469460368156
test acc: 0.018352776765823364
Training epoch=480 train loss=554.0471801757812 train acc=0.015735475346446037
test acc: 0.018352776765823364
Training epoch=490 train loss=684.1243896484375 train acc=0.015812451019883156
test acc: 0.018352776765823364
Training epoch=500 train loss=369.25408935546875 train acc=0.015614519827067852
test acc: 0.018352776765823364
Training epoch=510 train loss=477.6162109375 train acc=0.015702487900853157
test acc: 0.018352776765823364
Training epoch=520 train loss=431.3470458984375 train acc=0.016109345480799675
test acc: 0.018352776765823364
Training epoch=530 train loss=211.6956024169922 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=540 train loss=666.2645874023438 train acc=0.015625515952706337
test acc: 0.018352776765823364
Training epoch=550 train loss=315.9358215332031 train acc=0.015504557639360428
test acc: 0.018352776765823364
Training epoch=560 train loss=264.5771789550781 train acc=0.015449577011168003
test acc: 0.018352776765823364
Training epoch=570 train loss=226.6393280029297 train acc=0.015350611880421638
test acc: 0.018352776765823364
Training epoch=580 train loss=154.70286560058594 train acc=0.015504558570683002
test acc: 0.018352776765823364
Training epoch=590 train loss=297.6166687011719 train acc=0.015251646749675274
test acc: 0.018352776765823364
Training epoch=600 train loss=149.0151824951172 train acc=0.015449577011168003
test acc: 0.018352776765823364
Training epoch=610 train loss=314.4405212402344 train acc=0.015361608006060123
test acc: 0.018352776765823364
Training epoch=620 train loss=153.7670135498047 train acc=0.015317622572183609
test acc: 0.018352776765823364
Training epoch=630 train loss=172.78549194335938 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=640 train loss=97.95993041992188 train acc=0.015163677744567394
test acc: 0.018352776765823364
Training epoch=650 train loss=107.60059356689453 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=660 train loss=122.03556060791016 train acc=0.015460572205483913
test acc: 0.018352776765823364
Training epoch=670 train loss=634.636962890625 train acc=0.01510869525372982
test acc: 0.018352776765823364
Training epoch=680 train loss=108.26631927490234 train acc=0.015196666121482849
test acc: 0.018352776765823364
Training epoch=690 train loss=104.51615905761719 train acc=0.015163675881922245
test acc: 0.018352776765823364
Training epoch=700 train loss=115.58907318115234 train acc=0.015163675881922245
test acc: 0.018352776765823364
Training epoch=710 train loss=369.38873291015625 train acc=0.015174674801528454
test acc: 0.018352776765823364
Training epoch=720 train loss=91.96066284179688 train acc=0.01505371555685997
test acc: 0.018352776765823364
Training epoch=730 train loss=95.36050415039062 train acc=0.015218658372759819
test acc: 0.018352776765823364
Training epoch=740 train loss=105.92737579345703 train acc=0.015317624434828758
test acc: 0.018352776765823364
Training epoch=750 train loss=59.12226867675781 train acc=0.015141686424612999
test acc: 0.018352776765823364
Training epoch=760 train loss=117.86026000976562 train acc=0.01515268161892891
test acc: 0.018352776765823364
Training epoch=770 train loss=291.3061218261719 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=780 train loss=159.56521606445312 train acc=0.01506471261382103
test acc: 0.018352776765823364
Training epoch=790 train loss=86.24385833740234 train acc=0.01514168456196785
test acc: 0.018352776765823364
Training epoch=800 train loss=416.1731262207031 train acc=0.015075708739459515
test acc: 0.018352776765823364
Training epoch=810 train loss=208.1509552001953 train acc=0.015130690298974514
test acc: 0.018352776765823364
Training epoch=820 train loss=66.58364868164062 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=830 train loss=186.26687622070312 train acc=0.015031723305583
test acc: 0.018352776765823364
Training epoch=840 train loss=257.361572265625 train acc=0.01506471261382103
test acc: 0.018352776765823364
Training epoch=850 train loss=66.5474853515625 train acc=0.015130688436329365
test acc: 0.018352776765823364
Training epoch=860 train loss=219.64268493652344 train acc=0.01507570967078209
test acc: 0.018352776765823364
Training epoch=870 train loss=81.72249603271484 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=880 train loss=115.5125732421875 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=890 train loss=968.2783203125 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=900 train loss=50.06705856323242 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=910 train loss=501.2398986816406 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=920 train loss=40.806785583496094 train acc=0.015042721293866634
test acc: 0.018352776765823364
Training epoch=930 train loss=38.38389587402344 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=940 train loss=51.19314193725586 train acc=0.014888773672282696
test acc: 0.018352776765823364
Training epoch=950 train loss=282.293212890625 train acc=0.01498774066567421
test acc: 0.018352776765823364
Training epoch=960 train loss=348.9414978027344 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=970 train loss=63.99274444580078 train acc=0.01493275910615921
test acc: 0.018352776765823364
Training epoch=980 train loss=50.42446517944336 train acc=0.014921761117875576
test acc: 0.018352776765823364
Training epoch=990 train loss=171.4427032470703 train acc=0.01494375430047512
test acc: 0.018352776765823364
Namespace(confidence_threshold=0.75, dataset='ogbn-arxiv', dropout=0.5, early_stopping=10, epochs=1000, exp_id='arxiv_std_gcn_0', exp_times='9', feature_normalize='True', few_label_number=10, few_label_seed=9, hidden_list='[256,256,256]', learning_rate=0.001, max_degree=3, model='gcn', standard_split='True', weight_decay=0.0, with_psuedo_loss='False')
(169343, 40)
(169343, 169343)
(169343, 128)
adj: (169343, 169343)
features: (169343, 128)
y: (169343, 40) (169343, 40) (169343, 40)
mask: (169343,) (169343,) (169343,)
x : tensor([[-0.0151, -0.0137, -0.0189,  ...,  0.0451, -0.0450, -0.0365],
        [-0.0580, -0.0329, -0.1515,  ...,  0.0319, -0.1733, -0.1402],
        [-0.0221, -0.0064, -0.0505,  ...,  0.0302,  0.0323, -0.0385],
        ...,
        [-0.0747, -0.0124, -0.1362,  ...,  0.0384, -0.0547, -0.0492],
        [-0.0492,  0.0146, -0.0896,  ..., -0.0318, -0.0147, -0.1339],
        [-0.0113,  0.1018, -0.0611,  ...,  0.0458,  0.0294, -0.0345]],
       device='cuda:0')
sp: tensor(indices=tensor([[     0,      1,      0,  ...,  75409, 138515, 169342],
                       [     0,      0,      1,  ..., 169342, 169342, 169342]]),
       values=tensor([0.5000, 0.3536, 0.3536,  ..., 0.0259, 0.0808, 0.0588]),
       device='cuda:0', size=(169343, 169343), nnz=2484941,
       layout=torch.sparse_coo)
input dim: 128
output dim: 40
num_features_nonzero: 0
Training epoch=0 train loss=20046.03515625 train acc=0.01925424113869667
test acc: 0.006995453033596277
Training epoch=10 train loss=16163.9296875 train acc=0.03687005862593651
test acc: 0.035038989037275314
Training epoch=20 train loss=13441.9453125 train acc=0.06052275374531746
test acc: 0.061025042086839676
Training epoch=30 train loss=17250.01953125 train acc=0.06873687356710434
test acc: 0.0703660324215889
Training epoch=40 train loss=14011.5205078125 train acc=0.048229072242975235
test acc: 0.0571158193051815
Training epoch=50 train loss=13095.380859375 train acc=0.05802663043141365
test acc: 0.049276791512966156
Training epoch=60 train loss=12010.72265625 train acc=0.06276597082614899
test acc: 0.04283686727285385
Training epoch=70 train loss=11044.4873046875 train acc=0.05357319489121437
test acc: 0.04277513921260834
Training epoch=80 train loss=9974.595703125 train acc=0.047877196222543716
test acc: 0.04390675574541092
Training epoch=90 train loss=9450.4306640625 train acc=0.05812560021877289
test acc: 0.044338829815387726
Training epoch=100 train loss=9769.9541015625 train acc=0.041730355471372604
test acc: 0.04518239572644234
Training epoch=110 train loss=7963.9775390625 train acc=0.0643274188041687
test acc: 0.03647923097014427
Training epoch=120 train loss=7520.9658203125 train acc=0.048042137175798416
test acc: 0.03189103677868843
Training epoch=130 train loss=6125.62548828125 train acc=0.042027249932289124
test acc: 0.02409316413104534
Training epoch=140 train loss=5361.80517578125 train acc=0.05072519928216934
test acc: 0.0211098063737154
Training epoch=150 train loss=5177.71875 train acc=0.037617798894643784
test acc: 0.020924635231494904
Training epoch=160 train loss=5825.16162109375 train acc=0.03878339007496834
test acc: 0.02014279179275036
Training epoch=170 train loss=4089.084228515625 train acc=0.031295016407966614
test acc: 0.019196344539523125
Training epoch=180 train loss=4289.009765625 train acc=0.027204452082514763
test acc: 0.0187025498598814
Training epoch=190 train loss=2749.856689453125 train acc=0.03630925714969635
test acc: 0.0184968002140522
Training epoch=200 train loss=3083.5615234375 train acc=0.022575076669454575
test acc: 0.018435075879096985
Training epoch=210 train loss=2554.62890625 train acc=0.024268481880426407
test acc: 0.018393926322460175
Training epoch=220 train loss=1857.79296875 train acc=0.024147523567080498
test acc: 0.018393926322460175
Training epoch=230 train loss=1556.1375732421875 train acc=0.020958643406629562
test acc: 0.018352776765823364
Training epoch=240 train loss=2054.715087890625 train acc=0.020243894308805466
test acc: 0.01837335154414177
Training epoch=250 train loss=1698.01220703125 train acc=0.019914012402296066
test acc: 0.01837335154414177
Training epoch=260 train loss=1533.4918212890625 train acc=0.019815044477581978
test acc: 0.01837335154414177
Training epoch=270 train loss=1515.5185546875 train acc=0.01949615590274334
test acc: 0.018352776765823364
Training epoch=280 train loss=1302.9237060546875 train acc=0.018605470657348633
test acc: 0.018352776765823364
Training epoch=290 train loss=1598.838134765625 train acc=0.018429532647132874
test acc: 0.018352776765823364
Training epoch=300 train loss=1109.285888671875 train acc=0.017967693507671356
test acc: 0.018352776765823364
Training epoch=310 train loss=1154.7347412109375 train acc=0.018418535590171814
test acc: 0.018352776765823364
Training epoch=320 train loss=1276.6610107421875 train acc=0.017582830041646957
test acc: 0.018352776765823364
Training epoch=330 train loss=1667.7474365234375 train acc=0.017725778743624687
test acc: 0.018352776765823364
Training epoch=340 train loss=1022.2053833007812 train acc=0.01721995510160923
test acc: 0.018352776765823364
Training epoch=350 train loss=1043.9451904296875 train acc=0.01709899678826332
test acc: 0.018352776765823364
Training epoch=360 train loss=524.2611083984375 train acc=0.01723095029592514
test acc: 0.018352776765823364
Training epoch=370 train loss=1200.01318359375 train acc=0.01713198609650135
test acc: 0.018352776765823364
Training epoch=380 train loss=1028.7113037109375 train acc=0.016725128516554832
test acc: 0.018352776765823364
Training epoch=390 train loss=997.7794799804688 train acc=0.016604172065854073
test acc: 0.018352776765823364
Training epoch=400 train loss=1138.5433349609375 train acc=0.016527198255062103
test acc: 0.018352776765823364
Training epoch=410 train loss=439.981201171875 train acc=0.016307277604937553
test acc: 0.018352776765823364
Training epoch=420 train loss=384.5028381347656 train acc=0.016010379418730736
test acc: 0.018352776765823364
Training epoch=430 train loss=1098.0645751953125 train acc=0.016131337732076645
test acc: 0.018352776765823364
Training epoch=440 train loss=850.0972290039062 train acc=0.016087353229522705
test acc: 0.018352776765823364
Training epoch=450 train loss=582.59130859375 train acc=0.015911415219306946
test acc: 0.018352776765823364
Training epoch=460 train loss=413.7496032714844 train acc=0.015955399721860886
test acc: 0.018352776765823364
Training epoch=470 train loss=339.73150634765625 train acc=0.015757469460368156
test acc: 0.018352776765823364
Training epoch=480 train loss=554.0471801757812 train acc=0.015735475346446037
test acc: 0.018352776765823364
Training epoch=490 train loss=684.1243896484375 train acc=0.015812451019883156
test acc: 0.018352776765823364
Training epoch=500 train loss=369.25408935546875 train acc=0.015614519827067852
test acc: 0.018352776765823364
Training epoch=510 train loss=477.6162109375 train acc=0.015702487900853157
test acc: 0.018352776765823364
Training epoch=520 train loss=431.3470458984375 train acc=0.016109345480799675
test acc: 0.018352776765823364
Training epoch=530 train loss=211.6956024169922 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=540 train loss=666.2645874023438 train acc=0.015625515952706337
test acc: 0.018352776765823364
Training epoch=550 train loss=315.9358215332031 train acc=0.015504557639360428
test acc: 0.018352776765823364
Training epoch=560 train loss=264.5771789550781 train acc=0.015449577011168003
test acc: 0.018352776765823364
Training epoch=570 train loss=226.6393280029297 train acc=0.015350611880421638
test acc: 0.018352776765823364
Training epoch=580 train loss=154.70286560058594 train acc=0.015504558570683002
test acc: 0.018352776765823364
Training epoch=590 train loss=297.6166687011719 train acc=0.015251646749675274
test acc: 0.018352776765823364
Training epoch=600 train loss=149.0151824951172 train acc=0.015449577011168003
test acc: 0.018352776765823364
Training epoch=610 train loss=314.4405212402344 train acc=0.015361608006060123
test acc: 0.018352776765823364
Training epoch=620 train loss=153.7670135498047 train acc=0.015317622572183609
test acc: 0.018352776765823364
Training epoch=630 train loss=172.78549194335938 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=640 train loss=97.95993041992188 train acc=0.015163677744567394
test acc: 0.018352776765823364
Training epoch=650 train loss=107.60059356689453 train acc=0.015394596382975578
test acc: 0.018352776765823364
Training epoch=660 train loss=122.03556060791016 train acc=0.015460572205483913
test acc: 0.018352776765823364
Training epoch=670 train loss=634.636962890625 train acc=0.01510869525372982
test acc: 0.018352776765823364
Training epoch=680 train loss=108.26631927490234 train acc=0.015196666121482849
test acc: 0.018352776765823364
Training epoch=690 train loss=104.51615905761719 train acc=0.015163675881922245
test acc: 0.018352776765823364
Training epoch=700 train loss=115.58907318115234 train acc=0.015163675881922245
test acc: 0.018352776765823364
Training epoch=710 train loss=369.38873291015625 train acc=0.015174674801528454
test acc: 0.018352776765823364
Training epoch=720 train loss=91.96066284179688 train acc=0.01505371555685997
test acc: 0.018352776765823364
Training epoch=730 train loss=95.36050415039062 train acc=0.015218658372759819
test acc: 0.018352776765823364
Training epoch=740 train loss=105.92737579345703 train acc=0.015317624434828758
test acc: 0.018352776765823364
Training epoch=750 train loss=59.12226867675781 train acc=0.015141686424612999
test acc: 0.018352776765823364
Training epoch=760 train loss=117.86026000976562 train acc=0.01515268161892891
test acc: 0.018352776765823364
Training epoch=770 train loss=291.3061218261719 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=780 train loss=159.56521606445312 train acc=0.01506471261382103
test acc: 0.018352776765823364
Training epoch=790 train loss=86.24385833740234 train acc=0.01514168456196785
test acc: 0.018352776765823364
Training epoch=800 train loss=416.1731262207031 train acc=0.015075708739459515
test acc: 0.018352776765823364
Training epoch=810 train loss=208.1509552001953 train acc=0.015130690298974514
test acc: 0.018352776765823364
Training epoch=820 train loss=66.58364868164062 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=830 train loss=186.26687622070312 train acc=0.015031723305583
test acc: 0.018352776765823364
Training epoch=840 train loss=257.361572265625 train acc=0.01506471261382103
test acc: 0.018352776765823364
Training epoch=850 train loss=66.5474853515625 train acc=0.015130688436329365
test acc: 0.018352776765823364
Training epoch=860 train loss=219.64268493652344 train acc=0.01507570967078209
test acc: 0.018352776765823364
Training epoch=870 train loss=81.72249603271484 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=880 train loss=115.5125732421875 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=890 train loss=968.2783203125 train acc=0.01498773880302906
test acc: 0.018352776765823364
Training epoch=900 train loss=50.06705856323242 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=910 train loss=501.2398986816406 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=920 train loss=40.806785583496094 train acc=0.015042721293866634
test acc: 0.018352776765823364
Training epoch=930 train loss=38.38389587402344 train acc=0.015086703933775425
test acc: 0.018352776765823364
Training epoch=940 train loss=51.19314193725586 train acc=0.014888773672282696
test acc: 0.018352776765823364
Training epoch=950 train loss=282.293212890625 train acc=0.01498774066567421
test acc: 0.018352776765823364
Training epoch=960 train loss=348.9414978027344 train acc=0.015009731985628605
test acc: 0.018352776765823364
Training epoch=970 train loss=63.99274444580078 train acc=0.01493275910615921
test acc: 0.018352776765823364
Training epoch=980 train loss=50.42446517944336 train acc=0.014921761117875576
test acc: 0.018352776765823364
Training epoch=990 train loss=171.4427032470703 train acc=0.01494375430047512
test acc: 0.018352776765823364
Traceback (most recent call last):
  File "execute_experimens.py", line 83, in <module>
    ms=5, mfc="c", mec="r", capsize=7, capthick=8)
  File "/home/sm2/miniconda3/envs/gcns/lib/python3.7/site-packages/matplotlib/pyplot.py", line 2593, in errorbar
    **({"data": data} if data is not None else {}), **kwargs)
  File "/home/sm2/miniconda3/envs/gcns/lib/python3.7/site-packages/matplotlib/__init__.py", line 1438, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/sm2/miniconda3/envs/gcns/lib/python3.7/site-packages/matplotlib/axes/_axes.py", line 3453, in errorbar
    lower, upper = extract_err('y', yerr, y, lolims, uplims)
  File "/home/sm2/miniconda3/envs/gcns/lib/python3.7/site-packages/matplotlib/axes/_axes.py", line 3404, in extract_err
    f"{name}err must be a scalar or a 1D or (2, n) array-like")
ValueError: yerr must be a scalar or a 1D or (2, n) array-like
